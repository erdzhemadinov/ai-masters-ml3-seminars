{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnIVc28YITvO"
   },
   "source": [
    "# 05. Обучение CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jL3TJmvIe4w",
    "tags": []
   },
   "source": [
    "## План\n",
    "1. CIFAR10: baseline\n",
    "2. Просто добавим аугментаций\n",
    "3. Pretrained vs from scratch\n",
    "4. LR scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CZp6_cCKXBQ"
   },
   "source": [
    "## 1. CIFAR10: baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8mPPXr6ILZN"
   },
   "source": [
    "Мы уже умеем составлять несложные архитектуры нейросетей и обучать их на произвольных (картиночных) датасетах.\n",
    "На этом семинаре мы поговорим о том, какие ручки можно покрутить, чтобы улучшать результаты.\n",
    "\n",
    "Перечислим некоторые (но точно не все) из таких ручек:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Параметры модели\n",
    "  * тип архитектуры\n",
    "    * семейство (ResNet / EfficientNet / ...)\n",
    "    * размер модели (ResNet18 / ResNet101?)\n",
    "  * число обучаемых слоёв\n",
    "    * warmup при дообучении\n",
    "  * ...\n",
    "\n",
    "* Параметры оптимизации\n",
    "  * собственно оптимизатор (SGD / Adam + вариации / ...)\n",
    "  * learning rate\n",
    "    * scheduling\n",
    "  * momentum\n",
    "  * weight decay\n",
    "  * ...\n",
    "  \n",
    "* Параметры данных\n",
    "  * веса классов / сэмплирование\n",
    "  * набор и сила аугментаций\n",
    "  * добавление / чистках\n",
    "  * ...\n",
    "\n",
    "* Параметры обучения\n",
    "  * размер батча\n",
    "  * функция потерь\n",
    "  * целевая метрика (да, не `val_loss`-ом единым)  \n",
    "  * критерий остановки\n",
    "  * ...\n",
    "  \n",
    "* ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но решение любой задачи начинается с построения бейзлайна!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENjd7aWaO1mV"
   },
   "source": [
    "### 1.1. Получаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-AnWHvVKNYw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если еще не скачивали данные:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yk8ukXPuCKYU",
    "outputId": "82a42d40-5a58-48b2-c71d-97f1261c92b3"
   },
   "source": [
    "%%capture\n",
    "!rm -r cifar10\n",
    "!wget https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "!tar -xvf cifar-10-python.tar.gz\n",
    "\n",
    "def refactor_cifar10_data(root, output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    filenames = []\n",
    "    labels = []\n",
    "    for i in range(1, 6):\n",
    "        fname = os.path.join(root, f\"data_batch_{i}\")\n",
    "        with open(fname, \"rb\") as fp:\n",
    "            data_dict = pickle.load(fp, encoding=\"bytes\")\n",
    "        labels.extend(data_dict[b\"labels\"])\n",
    "        for j in tqdm.trange(len(data_dict[b\"labels\"])):\n",
    "            output_fn = os.path.join(output_dir, \n",
    "                                     f\"batch_{str(i).zfill(2)}_image_{str(j).zfill(4)}.jpg\")\n",
    "            filenames.append(output_fn)\n",
    "\n",
    "            image = data_dict[b\"data\"][j].reshape((3, 32, 32)).transpose(1, 2, 0)\n",
    "            cv2.imwrite(output_fn, cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "    return filenames, labels\n",
    "\n",
    "filenames, labels = refactor_cifar10_data(\"./cifar-10-batches-py\", \"cifar10\")\n",
    "\n",
    "with open(\"cifar10_labels.csv\", \"wt\") as fp:\n",
    "    for fn, label in zip(filenames, labels):\n",
    "        line = f\"{fn},{label}\\n\"\n",
    "        fp.write(line)\n",
    "        \n",
    "!rm -r cifar-10-batches-py\n",
    "!rm -r cifar-10-python.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если уже скачали:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "filenames = []\n",
    "labels = []\n",
    "\n",
    "with open(\"cifar10_labels.csv\", \"rt\") as fp:\n",
    "    for line in fp:\n",
    "        fn, label = line.strip().split(',')\n",
    "        filenames.append(fn)\n",
    "        labels.append(int(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(filenames), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kEx_CN2RONCU"
   },
   "outputs": [],
   "source": [
    "cifar10_class_map = {\n",
    "    0: \"airplane\",\n",
    "    1: \"automobile\",\n",
    "    2: \"bird\",\n",
    "    3: \"cat\", \n",
    "    4: \"deer\",\n",
    "    5: \"dog\",\n",
    "    6: \"frog\", \n",
    "    7: \"horse\",\n",
    "    8: \"ship\",\n",
    "    9: \"truck\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGF99FATIMOm"
   },
   "source": [
    "### 1.2. Собираем датасет и знакомимся с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WFPI1sXxIMqU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "909xWQ8YKLLw"
   },
   "outputs": [],
   "source": [
    "class CIFAR10Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, filenames, labels, split, transforms):\n",
    "        self.filenames = filenames\n",
    "        self.labels = labels\n",
    "        self.split = split\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        image = cv2.imread(self.filenames[i])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.\n",
    "        \n",
    "        # v NOTE THIS v\n",
    "        image_tensor = self.transforms(image)\n",
    "        # ^ NOTE THIS ^\n",
    "\n",
    "        label = self.labels[i]\n",
    "        \n",
    "        return image_tensor, label\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(items):\n",
    "        images_batch = torch.zeros(len(items), 3, 32, 32)\n",
    "        labels_batch = torch.zeros(len(items))\n",
    "        for i, item in enumerate(items):\n",
    "            images_batch[i] = item[0]\n",
    "            labels_batch[i] = item[1]\n",
    "        return images_batch.float(), labels_batch.long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прежде мы при обращении к картинкам через датасет обрабатывали их руками (конвертировали в тензор, например).\n",
    "Можно (и вообще говоря нужно) делать это через механизм трансформаций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-Qah-YVMIOk"
   },
   "outputs": [],
   "source": [
    "transforms_simple = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.5, 0.5, 0.5], [0.25, 0.25, 0.25])  # should've computed this on train data, but...\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь мы использовали для трансформаций модуль `torhvision.transforms`, но есть и альтернативы (о них чуть ниже).\n",
    "Пока что мы ограничились включением в трансформации только базовых операций - конвертации в тензор и нормализации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6hxTxQywLhea"
   },
   "outputs": [],
   "source": [
    "filenames_train, filenames_val, labels_train,  labels_val = train_test_split(filenames, labels, train_size=0.9, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GSZl2qJJL5zA"
   },
   "outputs": [],
   "source": [
    "dataset_train = CIFAR10Dataset(filenames_train, labels_train, \"train\", transforms_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обратной конвертации в картинку (чтобы отрисовать ее, например), нужно сделать \"де-нормализацию\":\n",
    "\n",
    "**Задача**: реализовать функцию `tensor_to_image`, получающую на вход нормализованный тензор `(3, h, w)`, возвращающую де-нормализованный массив `(h, w, 3)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4_f5l7CTM83I"
   },
   "outputs": [],
   "source": [
    "def tensor_to_image(tensor):\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END OF YOUR CODE\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.random.uniform(size=(32, 32, 3))\n",
    "tensor = (torch.from_numpy(image).permute(2, 0, 1) - 0.5) / 0.25\n",
    "\n",
    "np.testing.assert_array_equal(image, tensor_to_image(tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим глазами на данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 862
    },
    "id": "Ukptd7M9L6zz",
    "outputId": "4d72cb68-df9a-4164-afbf-5f9b69c94c27"
   },
   "outputs": [],
   "source": [
    "indexes_to_show = np.random.choice(len(dataset_train), size=64, replace=False)\n",
    "\n",
    "plt.figure(figsize=(18, 14))\n",
    "for i, index in enumerate(indexes_to_show):\n",
    "    tensor, label = dataset_train[index]\n",
    "    image = tensor_to_image(tensor)\n",
    "    plt.subplot(8, 8, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis(False)\n",
    "    plt.title(f\"GT: {label} ({cifar10_class_map[label]})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4EFjIrKjPJ50"
   },
   "source": [
    "Обычно полезно провести разведывательный анализ данных (EDA).\n",
    "Сейчас ограничимся тем, что посмотрим на распределение количества картинок по классам.\n",
    "\n",
    "**Задача**: любым удобным способ вывести количество изображений по каждому классу в обучающем датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l3jx-D58P-1_",
    "outputId": "ca33cfd9-39fd-48cb-9d2e-c6de07e07308"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "### END OF YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забудем собрать валидационный датасет, и двинемся дальше:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L8exmChjPmIp"
   },
   "outputs": [],
   "source": [
    "dataset_val = CIFAR10Dataset(filenames_val, labels_val, \"val\", transforms_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TpyBiwm1Q2-3"
   },
   "source": [
    "### 1.3. Собираем модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3THP9pzRIcP"
   },
   "source": [
    "Начнем, как и собирались, с бейзлайна.\n",
    "Бейзлайн - это какое-то простое решение, которые конкретно вы можете быстро реализовать и проверить.\n",
    "Чуть позже бейзлайном вы будете считать уже ResNet34, но пока напишем его ручками.\n",
    "\n",
    "conv -> bn -> relu -> conv -> bn -> relu (pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: реализуйте метод для инициализации блока сверточной сети. Блок должен работать так:\n",
    "* conv 3x3 / in_channels -> out_channels\n",
    "* batchnorm2d\n",
    "* relu\n",
    "* conv 3x3\n",
    "* batchnorm2d\n",
    "* relu\n",
    "* (optionally) maxpool 2x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o1jQC25eP4R9"
   },
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, pool=True):\n",
    "        super(CNNBlock, self).__init__()\n",
    "\n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "        ### END OF YOUR CODE\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберем из этих блоков сеть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5AXYKl0ATBSO"
   },
   "outputs": [],
   "source": [
    "cnn_baseline = nn.Sequential(\n",
    "    CNNBlock(3, 32),\n",
    "    CNNBlock(32, 64),\n",
    "    CNNBlock(64, 128),\n",
    "    CNNBlock(128, 256),\n",
    "    CNNBlock(256, 512),\n",
    "    \n",
    "    # v NOTE THIS\n",
    "    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "    # ^ NOTE THIS ^\n",
    "    \n",
    "    nn.Flatten(),\n",
    "    nn.Linear(512, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8adj93WgTtll",
    "outputId": "7edac7b1-9226-429b-b4d6-06402256cedf"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(4, 3, 32, 32)\n",
    "y = cnn_baseline(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XnXxvwS-UDUq"
   },
   "source": [
    "### 1.4. Учим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H6GZw6u4UDCU",
    "outputId": "3e6c95c9-a990-4e20-85f1-e32ad625a0a9"
   },
   "outputs": [],
   "source": [
    "num_epochs = 8\n",
    "batch_size = 128\n",
    "lr = 3e-4\n",
    "\n",
    "device = torch.device(\"cuda:7\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trrW6vpoT0Qs"
   },
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              collate_fn=CIFAR10Dataset.collate_fn, \n",
    "                              batch_size=batch_size, shuffle=True, drop_last=True, \n",
    "                              num_workers=4, pin_memory=True)\n",
    "\n",
    "dataloader_val = DataLoader(dataset_val, \n",
    "                            collate_fn=CIFAR10Dataset.collate_fn, \n",
    "                            batch_size=batch_size, shuffle=False, drop_last=False, \n",
    "                            num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bSngwHiWplz"
   },
   "source": [
    "Инициализируйте сами необходимый лосс и оптимизатор Adam, взяв готовые из `pytorch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "chiFfTDuWpAd"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "# loss_fn = ...\n",
    "\n",
    "### END OF YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-pkPqJP3Wxey"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "# optimizer = ...\n",
    "\n",
    "### END OF YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bk4PdC_VVT5z"
   },
   "source": [
    "Раньше у нас были отдельные методы для обучения/валидации - теперь мы готовы сделать из них один:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFQKkzQ_T1ff"
   },
   "outputs": [],
   "source": [
    "def run_epoch(stage, model, dataloader, loss_fn, optimizer, epoch, device):\n",
    "    \n",
    "    # v NOTE THIS v\n",
    "    if stage == \"train\":\n",
    "        model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "    else:\n",
    "        torch.set_grad_enabled(False)\n",
    "        model.eval()\n",
    "    # ^ NOTE THIS ^\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    losses = []\n",
    "    for batch in tqdm.tqdm(dataloader, total=len(dataloader), desc=f\"epoch: {str(epoch).zfill(3)} | {stage:5}\"):\n",
    "        xs, ys_true = batch\n",
    "                \n",
    "        ys_pred = model(xs.to(device))\n",
    "        loss = loss_fn(ys_pred, ys_true.to(device))\n",
    "\n",
    "        if stage == \"train\":\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "                \n",
    "        losses.append(loss.detach().cpu().item())\n",
    "\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме того, мы готовы к чему-то большему, чем просто брать последний чекпоинт модели.\n",
    "Будем контролировать значение целевой метрики (сегодня это `val_loss`), и сохранять чекпоинт модели в случае, если он лучший.\n",
    "\n",
    "Для этого вспомните-ка, как сохранять и загружать веса моделей.\n",
    "\n",
    "**Задание**: реализуйте функции `save_checkpoint()` & `load_checkpoint()`. На входе объект модели и имя файла, на выходе - ничего (но в случае загрузки модель должна получить новые веса)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wQfX64IgXT2t"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(model, filename):\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END OF YOUR CODE\n",
    "\n",
    "\n",
    "def load_checkpoint(model, filename):\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END OF YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DZvT4IqTX2pX"
   },
   "outputs": [],
   "source": [
    "my_model = nn.Linear(100, 1)\n",
    "my_model.weight *= 1e6\n",
    "save_checkpoint(my_model, \"test.pth.tar\")\n",
    "\n",
    "my_model_new = nn.Linear(100, 1)\n",
    "load_checkpoint(my_model_new, \"test.pth.tar\")\n",
    "\n",
    "torch.testing.assert_allclose(my_model.weight, my_model_new.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Экспериментов у нас будет много, поэтому для экономии кода обернем все, что нужно для обучения, в функцию `run_experiment()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3yNx14QWT5Ff"
   },
   "outputs": [],
   "source": [
    "def run_experiment(model, dataloader_train, dataloader_val, loss_fn, optimizer, num_epochs, device, output_dir):\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    best_val_loss = np.inf\n",
    "    best_val_loss_epoch = -1\n",
    "    best_val_loss_fn = None\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = run_epoch(\"train\", model, dataloader_train, loss_fn, optimizer, epoch, device)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        val_loss = run_epoch(\"val\", model, dataloader_val, loss_fn, optimizer, epoch, device)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"epoch: {str(epoch).zfill(3)} | train_loss: {train_loss:5.3f}, val_loss: {val_loss:5.3f} (best: {best_val_loss:5.3f})\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "\n",
    "            best_val_loss = val_loss\n",
    "            best_val_loss_epoch = epoch\n",
    "\n",
    "            output_fn = os.path.join(output_dir, f\"epoch={str(epoch).zfill(2)}_valloss={best_val_loss:.3f}.pth.tar\")\n",
    "            save_checkpoint(model, output_fn)\n",
    "            print(f\"New checkpoint saved to {output_fn}\")\n",
    "\n",
    "            best_val_loss_fn = output_fn\n",
    "\n",
    "        print()\n",
    "\n",
    "    print (f\"Best val_loss = {best_val_loss:.3f} reached at epoch {best_val_loss_epoch}\")\n",
    "    load_checkpoint(model, best_val_loss_fn)\n",
    "\n",
    "    return train_losses, val_losses, best_val_loss, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JJeIJj6ShR3o",
    "outputId": "805bb264-b9c8-443a-c721-2ba42295431e"
   },
   "outputs": [],
   "source": [
    "train_losses_baseline, val_losses_baseline, best_val_loss_baseline, cnn_baseline = run_experiment(\n",
    "    cnn_baseline, dataloader_train, dataloader_val, loss_fn, optimizer, num_epochs, device, \"checkpoints_baseline\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bNCzakbVgTea"
   },
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses, title):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.title(title)\n",
    "    plt.plot(train_losses, label=\"train\")\n",
    "    plt.plot(val_losses, label=\"val\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "8aAy0lgUgj9i",
    "outputId": "c1bda83c-b46f-4d1a-84e8-a5cf4cc6c1c5"
   },
   "outputs": [],
   "source": [
    "plot_losses(train_losses_baseline, val_losses_baseline, title=\"cnn_baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем метрики:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p7Qte_Auem9C"
   },
   "outputs": [],
   "source": [
    "def collect_predictions(model, dataloader, device):\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    labels_all = []\n",
    "    probs_all = []\n",
    "    preds_all = []\n",
    "    for batch in tqdm.tqdm(dataloader, total=len(dataloader)):\n",
    "        images, labels = batch\n",
    "\n",
    "        logits = model(images.to(device)).cpu()\n",
    "        probs = logits.softmax(dim=1)\n",
    "        max_prob, max_prob_index = torch.max(probs, dim=1)\n",
    "\n",
    "        labels_all.extend(labels.numpy().tolist())\n",
    "        probs_all.extend(max_prob.numpy().tolist())\n",
    "        preds_all.extend(max_prob_index.numpy().tolist())\n",
    "    \n",
    "    return labels_all, probs_all, preds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mhfxMqxrfR-1",
    "outputId": "e76b248f-ae0d-430b-cd51-1f52a27cbb31"
   },
   "outputs": [],
   "source": [
    "train_labels, train_probs, train_preds = collect_predictions(cnn_baseline, dataloader_train, device)\n",
    "\n",
    "accuracy_train = accuracy_score(train_labels, train_preds)\n",
    "accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CYgbiM2gfxTh",
    "outputId": "368ae29b-a2aa-43e3-e277-583baa7e431b"
   },
   "outputs": [],
   "source": [
    "train_labels[:5], train_preds[:5], train_probs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GaPkI0jBgGvs",
    "outputId": "c86ebb62-b3a0-4ca6-ca09-268f10a27224"
   },
   "outputs": [],
   "source": [
    "val_labels, val_probs, val_preds = collect_predictions(cnn_baseline, dataloader_val, device)\n",
    "\n",
    "accuracy_val = accuracy_score(val_labels, val_preds)\n",
    "accuracy_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Просто добавим аугментаций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Одна из базовых вещей при обучении - это аугментации. Можно делать с помощью `torchvision.transforms`, а можно взять сторонние библиотеки - например, [`albumentations`](https://albumentations.ai/). Есть и [более необычные вещи](https://pytorch.org/vision/main/generated/torchvision.transforms.AutoAugment.html), но о них мы отдельно говорить не будем.\n",
    "\n",
    "С аугментациями можно переборщить, поэтому начнем с малого:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MmqzNYQjgMbl"
   },
   "outputs": [],
   "source": [
    "transforms_aug = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(degrees=15),\n",
    "    T.Normalize([0.5, 0.5, 0.5], [0.25, 0.25, 0.25])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GSZl2qJJL5zA"
   },
   "outputs": [],
   "source": [
    "dataset_aug_train = CIFAR10Dataset(filenames_train, labels_train, \"train\", transforms_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 862
    },
    "id": "Ukptd7M9L6zz",
    "outputId": "4d72cb68-df9a-4164-afbf-5f9b69c94c27"
   },
   "outputs": [],
   "source": [
    "indexes_to_show = np.random.choice(len(dataset_aug_train), size=64, replace=False)\n",
    "\n",
    "plt.figure(figsize=(18, 14))\n",
    "for i, index in enumerate(indexes_to_show):\n",
    "    tensor, label = dataset_aug_train[index]\n",
    "    image = tensor_to_image(tensor)\n",
    "    plt.subplot(8, 8, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.axis(False)\n",
    "    plt.title(f\"GT: {label} ({cifar10_class_map[label]})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на динамику обучения с аугментациями (обратите внимание, валидационный датасет остался прежним):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5AXYKl0ATBSO"
   },
   "outputs": [],
   "source": [
    "cnn_aug = nn.Sequential(\n",
    "    CNNBlock(3, 32),\n",
    "    CNNBlock(32, 64),\n",
    "    CNNBlock(64, 128),\n",
    "    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(128, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увеличим число эпох (забегая вперед - переобучение мы немного снизим, поэтому имеет смысл добавить итераций)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H6GZw6u4UDCU",
    "outputId": "3e6c95c9-a990-4e20-85f1-e32ad625a0a9"
   },
   "outputs": [],
   "source": [
    "num_epochs = 32\n",
    "batch_size = 128\n",
    "lr = 3e-4\n",
    "\n",
    "device = torch.device(\"cuda:7\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trrW6vpoT0Qs"
   },
   "outputs": [],
   "source": [
    "dataloader_aug_train = DataLoader(dataset_aug_train, \n",
    "                                  collate_fn=CIFAR10Dataset.collate_fn, \n",
    "                                  batch_size=batch_size, shuffle=True, drop_last=True, \n",
    "                                  num_workers=4, pin_memory=True)\n",
    "\n",
    "dataloader_val = DataLoader(dataset_val, \n",
    "                            collate_fn=CIFAR10Dataset.collate_fn, \n",
    "                            batch_size=batch_size, shuffle=False, drop_last=False, \n",
    "                            num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "chiFfTDuWpAd"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn_aug.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JJeIJj6ShR3o",
    "outputId": "805bb264-b9c8-443a-c721-2ba42295431e"
   },
   "outputs": [],
   "source": [
    "train_losses_aug, val_losses_aug, best_val_loss_aug, cnn_aug = run_experiment(\n",
    "    cnn_aug, dataloader_aug_train, dataloader_val, loss_fn, optimizer, num_epochs, device, \"checkpoints_aug\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "8aAy0lgUgj9i",
    "outputId": "c1bda83c-b46f-4d1a-84e8-a5cf4cc6c1c5"
   },
   "outputs": [],
   "source": [
    "plot_losses(train_losses_aug, val_losses_aug, title=\"cnn_aug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mhfxMqxrfR-1",
    "outputId": "e76b248f-ae0d-430b-cd51-1f52a27cbb31"
   },
   "outputs": [],
   "source": [
    "train_labels, train_probs, train_preds = collect_predictions(cnn_aug, dataloader_aug_train, device)\n",
    "\n",
    "accuracy_train = accuracy_score(train_labels, train_preds)\n",
    "accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GaPkI0jBgGvs",
    "outputId": "c86ebb62-b3a0-4ca6-ca09-268f10a27224"
   },
   "outputs": [],
   "source": [
    "val_labels, val_probs, val_preds = collect_predictions(cnn_aug, dataloader_val, device)\n",
    "\n",
    "accuracy_val = accuracy_score(val_labels, val_preds)\n",
    "accuracy_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pretrained & from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важнейший прием, которым следует овладеть - это пользоваться готовыми моделями :)\n",
    "\n",
    "Часто (*да почти всегда*) лучше учиться не со случайных весов. Если у вас в наличии есть модель, уже обученная на хоть сколько-нибудь смежном домене с целевым - надо брать и дообучаться с нее.\n",
    "\n",
    "Откуда брать модели?\n",
    "* [`torchvision.models`](https://pytorch.org/vision/0.8/models.html)\n",
    "* [`pytorch_image_models`](https://github.com/rwightman/pytorch-image-models)\n",
    "* ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models as M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet - база. Возьмем восемнадцатый:\n",
    "\n",
    "![resnet](https://velog.velcdn.com/images%2Fe_sin528%2Fpost%2Fe272c056-3dfa-4bb6-bfc9-b309d82df932%2FResNet18.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = M.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "y = resnet18(x)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как использовать готовую модель?\n",
    "* Заменить выходной слой на слой с нужным числом классов\n",
    "  * `timm` умеет это прямо при инициализации\n",
    "* Взять `feature_extractor` модели и навернуть сверху своих слоев\n",
    "  * `timm` опять же позволяет это легко сделать\n",
    "  \n",
    "У нас особенный случай: ResNet18 уменьшает размер входного изображения в 64 раза, а у нас картинки 32х32. Как быть?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "y = resnet18(x)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Например, можно взять и выдрать слои из модели и поместить в `Sequential`, приправив своими слоями сверху:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_finetuned = nn.Sequential(\n",
    "    resnet18.conv1,\n",
    "    resnet18.bn1,\n",
    "    resnet18.relu,\n",
    "    resnet18.maxpool,\n",
    "    resnet18.layer1,\n",
    "    resnet18.layer2,\n",
    "\n",
    "    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(128, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_finetuned(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь про обучение. Поскольку у нас есть частично обученные веса на входе (из ResNet) и полностью необученные на выходе (свои) веса, градиенты через конец сети могут быть очень шумными. Поэтому есть практика обучения только новых голов в течение пары эпох, а затем полное обучение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_finetuned[0].weight.requires_grad, cnn_finetuned[-1].weight.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Веса слоев можно заморозить ручками:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in cnn_finetuned:\n",
    "    layer.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_finetuned[0].weight.requires_grad, cnn_finetuned[-1].weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_finetuned[-1].requires_grad_(True)\n",
    "cnn_finetuned[-1].weight.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь к обучению:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H6GZw6u4UDCU",
    "outputId": "3e6c95c9-a990-4e20-85f1-e32ad625a0a9"
   },
   "outputs": [],
   "source": [
    "num_epochs = 32\n",
    "batch_size = 128\n",
    "lr = 3e-4\n",
    "\n",
    "device = torch.device(\"cuda:7\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bSngwHiWplz"
   },
   "source": [
    "Сначала 3 эпохи учим только последний слой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "chiFfTDuWpAd"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(cnn_finetuned[-1].parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JJeIJj6ShR3o",
    "outputId": "805bb264-b9c8-443a-c721-2ba42295431e"
   },
   "outputs": [],
   "source": [
    "train_losses_finetuned, val_losses_finetuned, best_val_loss_finetuned, cnn_finetuned = run_experiment(\n",
    "    cnn_finetuned, dataloader_aug_train, dataloader_val, loss_fn, optimizer, 3, device, \"checkpoints_finetuned\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь размораживаем всю сеть и учим целиком:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in cnn_finetuned:\n",
    "    layer.requires_grad_(True)\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn_finetuned.parameters(), lr=lr)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JJeIJj6ShR3o",
    "outputId": "805bb264-b9c8-443a-c721-2ba42295431e"
   },
   "outputs": [],
   "source": [
    "train_losses_finetuned, val_losses_finetuned, best_val_loss_finetuned, cnn_finetuned = run_experiment(\n",
    "    cnn_finetuned, dataloader_aug_train, dataloader_val, loss_fn, optimizer, num_epochs, device, \"checkpoints_finetuned\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "8aAy0lgUgj9i",
    "outputId": "c1bda83c-b46f-4d1a-84e8-a5cf4cc6c1c5"
   },
   "outputs": [],
   "source": [
    "plot_losses(train_losses_finetuned, val_losses_finetuned, title=\"cnn_finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mhfxMqxrfR-1",
    "outputId": "e76b248f-ae0d-430b-cd51-1f52a27cbb31"
   },
   "outputs": [],
   "source": [
    "train_labels, train_probs, train_preds = collect_predictions(cnn_finetuned, dataloader_aug_train, device)\n",
    "\n",
    "accuracy_train = accuracy_score(train_labels, train_preds)\n",
    "accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GaPkI0jBgGvs",
    "outputId": "c86ebb62-b3a0-4ca6-ca09-268f10a27224"
   },
   "outputs": [],
   "source": [
    "val_labels, val_probs, val_preds = collect_predictions(cnn_finetuned, dataloader_val, device)\n",
    "\n",
    "accuracy_val = accuracy_score(val_labels, val_preds)\n",
    "accuracy_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. LR scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последняя на сегодня - работа с LR.\n",
    "Из лекций вы могли запомнить, что варьирование LR при обучении (даже адаптивных методов) может достичь более высокого качества.\n",
    "\n",
    "![lrs](https://i.stack.imgur.com/UHYMw.png)\n",
    "\n",
    "`pytorch` предоставляет возможности и для этого."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.1. Обновление по сигналу от метрик (ReduceLROnPlateau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно изменять LR, основываясь на изменении целевой метрики.\n",
    "Если, например, лосс давно не падает, можно уменьшить LR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5AXYKl0ATBSO"
   },
   "outputs": [],
   "source": [
    "cnn_aug = nn.Sequential(\n",
    "    CNNBlock(3, 32),\n",
    "    CNNBlock(32, 64),\n",
    "    CNNBlock(64, 128),\n",
    "    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(128, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H6GZw6u4UDCU",
    "outputId": "3e6c95c9-a990-4e20-85f1-e32ad625a0a9"
   },
   "outputs": [],
   "source": [
    "num_epochs = 16\n",
    "batch_size = 128\n",
    "lr = 1\n",
    "\n",
    "device = torch.device(\"cuda:7\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "chiFfTDuWpAd"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn_aug.parameters(), lr=lr)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.1, patience=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(stage, model, dataloader, loss_fn, optimizer, epoch, device):\n",
    "\n",
    "    if stage == \"train\":\n",
    "        model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "    else:\n",
    "        torch.set_grad_enabled(False)\n",
    "        model.eval()\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    losses = []\n",
    "    for batch in tqdm.tqdm(dataloader, total=len(dataloader), desc=f\"epoch: {str(epoch).zfill(3)} | {stage:5}\"):\n",
    "        xs, ys_true = batch\n",
    "                \n",
    "        ys_pred = model(xs.to(device))\n",
    "        loss = loss_fn(ys_pred, ys_true.to(device))\n",
    "\n",
    "        if stage == \"train\":\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "                \n",
    "        losses.append(loss.detach().cpu().item())\n",
    "    \n",
    "    if stage == \"train\":\n",
    "        scheduler.step(np.mean(losses))\n",
    "\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bk4PdC_VVT5z"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JJeIJj6ShR3o",
    "outputId": "805bb264-b9c8-443a-c721-2ba42295431e"
   },
   "outputs": [],
   "source": [
    "train_losses_aug, val_losses_aug, best_val_loss_aug, cnn_aug = run_experiment(\n",
    "    cnn_aug, dataloader_aug_train, dataloader_val, loss_fn, optimizer, num_epochs, device, \"checkpoints_aug\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Обновление каждую эпоху (StepLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5AXYKl0ATBSO"
   },
   "outputs": [],
   "source": [
    "cnn_aug = nn.Sequential(\n",
    "    CNNBlock(3, 32),\n",
    "    CNNBlock(32, 64),\n",
    "    CNNBlock(64, 128),\n",
    "    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(128, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H6GZw6u4UDCU",
    "outputId": "3e6c95c9-a990-4e20-85f1-e32ad625a0a9"
   },
   "outputs": [],
   "source": [
    "num_epochs = 8\n",
    "batch_size = 128\n",
    "lr = 3e-4\n",
    "\n",
    "device = torch.device(\"cuda:7\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "chiFfTDuWpAd"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn_aug.parameters(), lr=lr)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(stage, model, dataloader, loss_fn, optimizer, epoch, device):\n",
    "\n",
    "    if stage == \"train\":\n",
    "        model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "    else:\n",
    "        torch.set_grad_enabled(False)\n",
    "        model.eval()\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    losses = []\n",
    "    for batch in tqdm.tqdm(dataloader, total=len(dataloader), desc=f\"epoch: {str(epoch).zfill(3)} | {stage:5}\"):\n",
    "        xs, ys_true = batch\n",
    "                \n",
    "        ys_pred = model(xs.to(device))\n",
    "        loss = loss_fn(ys_pred, ys_true.to(device))\n",
    "\n",
    "        if stage == \"train\":\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "                \n",
    "        losses.append(loss.detach().cpu().item())\n",
    "    \n",
    "    if stage == \"train\":\n",
    "        scheduler.step()\n",
    "\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bk4PdC_VVT5z"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JJeIJj6ShR3o",
    "outputId": "805bb264-b9c8-443a-c721-2ba42295431e"
   },
   "outputs": [],
   "source": [
    "train_losses_aug, val_losses_aug, best_val_loss_aug, cnn_aug = run_experiment(\n",
    "    cnn_aug, dataloader_aug_train, dataloader_val, loss_fn, optimizer, num_epochs, device, \"checkpoints_aug\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Обновление каждую итерацию (CosineAnnealingLR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть разные техники изменения LR по заданному закону. \n",
    "Например, [CosineAnnealing](https://paperswithcode.com/method/cosine-annealing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5AXYKl0ATBSO"
   },
   "outputs": [],
   "source": [
    "cnn_aug = nn.Sequential(\n",
    "    CNNBlock(3, 32),\n",
    "    CNNBlock(32, 64),\n",
    "    CNNBlock(64, 128),\n",
    "    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(128, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H6GZw6u4UDCU",
    "outputId": "3e6c95c9-a990-4e20-85f1-e32ad625a0a9"
   },
   "outputs": [],
   "source": [
    "num_epochs = 8\n",
    "batch_size = 128\n",
    "lr = 3e-4\n",
    "\n",
    "device = torch.device(\"cuda:7\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "chiFfTDuWpAd"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn_aug.parameters(), lr=lr)\n",
    "\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=int(len(dataloader_aug_train) + 1) * num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(stage, model, dataloader, loss_fn, optimizer, epoch, device):\n",
    "\n",
    "    if stage == \"train\":\n",
    "        model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "        print(\"lr (epoch start):\", scheduler.optimizer.param_groups[0]['lr'])\n",
    "    else:\n",
    "        torch.set_grad_enabled(False)\n",
    "        model.eval()\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    \n",
    "    losses = []\n",
    "    for batch in tqdm.tqdm(dataloader, total=len(dataloader), desc=f\"epoch: {str(epoch).zfill(3)} | {stage:5}\"):\n",
    "        xs, ys_true = batch\n",
    "                \n",
    "        ys_pred = model(xs.to(device))\n",
    "        loss = loss_fn(ys_pred, ys_true.to(device))\n",
    "\n",
    "        if stage == \"train\":\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "            \n",
    "        losses.append(loss.detach().cpu().item())\n",
    "    \n",
    "    if stage == \"train\":\n",
    "        print(\"lr (epoch end):\", scheduler.optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bk4PdC_VVT5z"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JJeIJj6ShR3o",
    "outputId": "805bb264-b9c8-443a-c721-2ba42295431e"
   },
   "outputs": [],
   "source": [
    "train_losses_aug, val_losses_aug, best_val_loss_aug, cnn_aug = run_experiment(\n",
    "    cnn_aug, dataloader_aug_train, dataloader_val, loss_fn, optimizer, num_epochs, device, \"checkpoints_aug\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоги"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Научились добавлять аугментации к обучению\n",
    "* Познакомились с методом использования предобученных моделей\n",
    "* Посмотрели на работу с LR scheduling в pytorch.\n",
    "\n",
    "Рекомендуется (в который раз) почитать пост от любимого нашего Andrej Karpathy [A Recipe for Training Neural Networks](https://karpathy.github.io/2019/04/25/recipe/) и обзорную статью (не самую новую, но все же) по трюкам для обучения моделей [Bag of Tricks for Image Classification with Convolutional Neural Networks](https://arxiv.org/pdf/1812.01187v2.pdf).\n",
    "\n",
    "Впереди ждет соревнование по классификации картинок на Kaggle, где вы сможете применить все полученные (и неполученные %)) знания на практике!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
