{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Нейросети и PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## План\n",
    "0. Переопределение `backward` (с прошлого семинара)\n",
    "1. Готовим обучение\n",
    "    1. Данные: `Dataset` & `DataLoader` \n",
    "    2. Модель: `nn.Module`\n",
    "    3. Рутина: все остальное\n",
    "2. Учим\n",
    "    1. Baseline\n",
    "    2. Stack more layers\n",
    "3. I/O\n",
    "4. Пример с картинками: MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Переопределение `backward`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g616ocbHv78t"
   },
   "source": [
    "Что, если нам хочется релизовать кастомный градиент для произвольной функции.\n",
    "\n",
    "Зачем?\n",
    "\n",
    " - Мы можем знать лучший способ посчитать градиент, чем делать бэкпроп для суперпозиции элементарных функций\n",
    " - Можем реализовать численно более устойчивый метод\n",
    " - Можем использовать функции из внешних библиотек\n",
    " - Использовать недифференцируемые функции?.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkYTgy6ZO_Ru"
   },
   "source": [
    "Рассмотрим сигмоиду:\n",
    "\n",
    "$$ \n",
    "  \\sigma(x) = \\frac{1}{1+e^{-x}}\n",
    "$$\n",
    "\n",
    "Если честно распишем суперпозицию функций, то получим:\n",
    "\n",
    "$$\n",
    "  \\sigma(x) = f_1 \\odot f_2  \\odot f_3 \\odot f_4(x), where \n",
    "$$\n",
    "\n",
    "$$\n",
    "f_1 = \\frac{1}{u}, f_2 = 1 + u, f_3 = \\exp(u), f_4 = -u\n",
    "$$\n",
    "\n",
    "Тогда:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\sigma}{\\partial x} = \\frac{\\partial \\sigma}{\\partial f_2}\\frac{\\partial f_2}{\\partial f_3}\n",
    "\\frac{\\partial f_3}{\\partial f_4}\n",
    "\\frac{\\partial f_4}{\\partial x}\n",
    "$$\n",
    "\n",
    "Но зная как устроена производная можно упростить:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\sigma}{\\partial x} = \\sigma(x)(1 - \\sigma(x))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRpFQBmuR-V_"
   },
   "source": [
    "Вручную задать градиени функции в библиотеке PyTorch можно создав дочерний класс от [`torch.autograd.Function`](https://pytorch.org/docs/stable/notes/extending.html#extending-torch-autograd).\n",
    "\n",
    "**Задание:**\n",
    "Реализуйте `forward()` и `backward()` методы для вычисления сигмоиды.\n",
    "* Аргумент `grad_output` - это градиент выхода графа по выходу данного слоя, вычисленный в результате backprop.\n",
    "* Метод `backward()` должен возвращать градиент выхода графа по входу данного слоя.\n",
    "* `ctx` - переменная контекста, позволяет сохранять значения переменных на `forward`-проходе для их вызова на `backward`-е\n",
    "    * Для этого у переменной контекста `ctx` есть метод [`save_for_backward()`](https://pytorch.org/docs/stable/generated/torch.autograd.function.FunctionCtx.save_for_backward.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1631815233191,
     "user": {
      "displayName": "Filipp Nikitin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gib7R6zFSdJ1Mn4MWbQTRjNvdPBqipg3uQtaNBFNg=s64",
      "userId": "00003629133353694743"
     },
     "user_tz": -180
    },
    "id": "okxelJTDO9_L"
   },
   "outputs": [],
   "source": [
    "class MySigmoid(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # val = ...\n",
    "        \n",
    "        # END OF YOUR CODE\n",
    "        return val\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # val, = ...\n",
    "        # grad = ...\n",
    "        \n",
    "        # END OF YOUR CODE\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch позволяет выполнить сравнение реализованного градиента с градиентом, посчитанным численно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1631815238628,
     "user": {
      "displayName": "Filipp Nikitin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gib7R6zFSdJ1Mn4MWbQTRjNvdPBqipg3uQtaNBFNg=s64",
      "userId": "00003629133353694743"
     },
     "user_tz": -180
    },
    "id": "n89TIozkVt27"
   },
   "outputs": [],
   "source": [
    "from torch.autograd import gradcheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 227,
     "status": "ok",
     "timestamp": 1631815280552,
     "user": {
      "displayName": "Filipp Nikitin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gib7R6zFSdJ1Mn4MWbQTRjNvdPBqipg3uQtaNBFNg=s64",
      "userId": "00003629133353694743"
     },
     "user_tz": -180
    },
    "id": "42MVi8npWlAR",
    "outputId": "15653e25-a437-4e4b-b093-5c610ee3e56f"
   },
   "outputs": [],
   "source": [
    "sigmoid = MySigmoid.apply\n",
    "x = torch.rand(2, requires_grad=True)\n",
    "print(gradcheck(sigmoid, x, eps=1e-4, atol=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# be sure to use double for better approximation\n",
    "x = torch.rand(2, requires_grad=True).double()\n",
    "print(gradcheck(sigmoid, x, eps=1e-6, atol=1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXYgzHcz7E_1"
   },
   "source": [
    "PyTorch умеет считать матрицу Якоби или матрицу Гессе для заданной функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 229,
     "status": "ok",
     "timestamp": 1631815491399,
     "user": {
      "displayName": "Filipp Nikitin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gib7R6zFSdJ1Mn4MWbQTRjNvdPBqipg3uQtaNBFNg=s64",
      "userId": "00003629133353694743"
     },
     "user_tz": -180
    },
    "id": "a65TCapsZBlf"
   },
   "outputs": [],
   "source": [
    "from torch.autograd.functional import hessian, jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 246,
     "status": "ok",
     "timestamp": 1631815519585,
     "user": {
      "displayName": "Filipp Nikitin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gib7R6zFSdJ1Mn4MWbQTRjNvdPBqipg3uQtaNBFNg=s64",
      "userId": "00003629133353694743"
     },
     "user_tz": -180
    },
    "id": "nS-DSoplZ6E_",
    "outputId": "db8a907c-8365-451f-d6f0-d1d186a54d97"
   },
   "outputs": [],
   "source": [
    "jacobian(sigmoid, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 215,
     "status": "ok",
     "timestamp": 1631815472226,
     "user": {
      "displayName": "Filipp Nikitin",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gib7R6zFSdJ1Mn4MWbQTRjNvdPBqipg3uQtaNBFNg=s64",
      "userId": "00003629133353694743"
     },
     "user_tz": -180
    },
    "id": "z_nXiJsFXoDR"
   },
   "outputs": [],
   "source": [
    "def sum_sigmoid(x):\n",
    "    return torch.sum(sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hessian(sum_sigmoid, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь - к обучению нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Готовим обучение "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общий подход к решению задачи на pytorch такой:\n",
    "1. Подготовить данные, реализовать (или использовать готовый) класс `Dataset`, наследуясь от `torch.utils.data.Dataset`, обернуть его в `torch.utils.data.DataLoader`.\n",
    "2. Реализовать (или взять ±готовую) модель, наследуясь от `torch.nn.Module`.\n",
    "3. Приготовить оптимизатор для весов модели (из `torch.optim` или свой) и лосс\n",
    "4. Написать код для рутины обучения, включающий обработку данных из `DataLoader`, прогон их через модель, вычисление лосса и обновление весов оптимизатором."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Данные: `Dataset` & `DataLoader`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Tutorial @ pytorch.org](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n",
    "\n",
    "Класс датасета предоставит нам интерфейс к данным:\n",
    "* Метод `__getitem__(self, i)` позволяет получить `i`-й элемент обучающей выборки, обычно пару (data, label).\n",
    "    * Также обязательным является определение метода `__len__(self)`.\n",
    "* Можно сделать так, чтобы экземпляр класса датасета просто возвращал исходные данные, а можно (нужно) добавить в него аугментирование данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dataset` - абстрактный класс, его нельзя использовать напрямую, а только через наследование:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим датасет поверх игрушечных данных с прошлого семинара:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "_a = np.random.uniform(1, 5)\n",
    "_b = np.random.uniform(-3, 3)\n",
    "_c = np.random.uniform(-3, 3)\n",
    "\n",
    "num_samples = 1000\n",
    "\n",
    "xs = np.random.uniform(-3, 3, size=num_samples)\n",
    "ys_clean = _a * xs ** 2 + _b * xs + _c\n",
    "ys_noise = np.random.normal(0, 1, size=len(ys_clean))\n",
    "ys = ys_clean + ys_noise\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(xs, ys, label=\"gt\", s=5)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, xs, ys):\n",
    "        super().__init__()\n",
    "        \n",
    "        if len(xs) != len(ys):\n",
    "            raise ValueError(f\"lens mismatch: {len(xs)} != {len(ys)}\")\n",
    "            \n",
    "        self.xs = xs\n",
    "        self.ys = ys\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.xs)\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        return (self.xs[i], self.ys[i])\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate_fn(items_list):\n",
    "        xs = torch.zeros(len(items_list), 1)\n",
    "        ys = torch.zeros(len(items_list), 1)\n",
    "\n",
    "        for i, (x, y) in enumerate(items_list):\n",
    "            xs[i] = x\n",
    "            ys[i] = y\n",
    "\n",
    "        return xs, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод `collate_fn` нужен не столько для самого датасета, сколько для оборачивания его в `DataLoader` - об этом чуть ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(xs, ys)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По датасету можно итерироваться (но вам это вряд ли будет нужно часто):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in dataset:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теоретически, для обучения достаточно уже объекта типа `Dataset`. Однако, для удобства и для автоматизации процессов перемешивания данных, формирования батчей и использования многопоточности есть удобный класс `DataLoader`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    drop_last=True, \n",
    "    collate_fn=dataset.collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Длина\" даталоадера - это количество батчей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К даталоадеру нельзя обращаться по индексу, но можно итерироваться по нему:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader:\n",
    "    xs, ys = batch\n",
    "    print(xs.shape, ys.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как именно происходит сборка батчей, покажем, реализовав свой игрушечный даталоадер с аналогичным функционалом:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**:\n",
    "Реализовать метод `__getitem__(self, i)`, который должен возвращать i-й батч. \n",
    "* Батч должен быть списком с числом элементов = равным числу элементов, возвращаемых датасетом при обращении по индексу (обычно 2 - данные и лейблы, но есть варианты).\n",
    "    * Каждый из элементов содержит не отдельный объект, а склеенный из отдельных объектов тензов\n",
    "    * Длина каждого = `batch_size`\n",
    "* Для сборки батча из отдельных элементов датасета используйте метод `self.dataset.collate_fn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataLoader:\n",
    "    \n",
    "    def __init__(self, dataset, batch_size, collate_fn):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.collate_fn = collate_fn\n",
    "        \n",
    "        self.indices = np.arange(len(dataset))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(dataset) // self.batch_size\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # indices = ...\n",
    "        # items = ...\n",
    "        # batch = ...\n",
    "        \n",
    "        # END OF YOUR CODE\n",
    "        \n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataloader = MyDataloader(dataset, batch_size=32, collate_fn=dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = my_dataloader[0]\n",
    "\n",
    "assert len(batch) == 2\n",
    "assert batch[0].shape == (32, 1)\n",
    "assert batch[1].shape == (32, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Про параметры `DataLoader`-а, которые мы сегодня не трогали (`pin_memory`, `num_workers`, ...), поговорим в другой раз."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.2. Модель: `nn.Module`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нейросетевые модели состоят из слоев, которые применяются ко входу (обычно) последовательно.\n",
    "Каждый слой должен быть наследником `torch.nn.Module`, чтобы сам pytorch понимал: перед ним слой нейросети, у него есть параметры, его надо уметь дифференцировать, и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание:**\n",
    "Реализовать недостающие куски кода в методах `__init__()` и `forward()`.\n",
    "* В `__init__()` должны быть инициализированы матрица `self.weights` (`out_dim x in_dim`) и вектор `bias` (или `None`).\n",
    "* В `forward()` они должны быть применены ко входу `x` (`batch x in_dim`).\n",
    "\n",
    "**NB**: Помните, что обычно обработка данных моделью происходит по батчам, т.е. даже если на вход придет 1 объект, у него будет размерность (`batch x in_dim`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLinear(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # self.weights = ...\n",
    "        # self.bias = ...\n",
    "        \n",
    "        # END OF YOUR CODE\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # output = ...\n",
    "        \n",
    "        # END OF YOUR CODE\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"CustomLinear({self.weights.shape[1]}, {self.weights.shape[0]}, bias={self.bias is not None})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = CustomLinear(8, 1)\n",
    "\n",
    "assert isinstance(linear.weights, torch.nn.Parameter)\n",
    "assert isinstance(linear.bias, torch.nn.Parameter)\n",
    "assert linear.weights.shape == (1, 8)\n",
    "assert linear.bias.shape == (1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, какие атрибуты и методы есть у нашего класса при наследовании от `nn.Module`.\n",
    "\n",
    "Во-первых, доступ к обучаемым (и не только) параметрам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in linear.parameters():\n",
    "    print(p)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in linear.named_parameters():\n",
    "    print(p)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для удобства чтения и отладки, часто полезно определить метод `__repr__()` для информативного вывода самого объекта:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важными полями являются индикатор `.training`: он показывает, в каком режиме находится модель - обучения или инференса.\n",
    "\n",
    "**Вопрос**: зачем?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.eval()\n",
    "linear.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.train()\n",
    "linear.training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB**: Выход из режима `training` не отключает вычисление градиентов!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы уже говорили в прошлый раз, вычисления можно производить не только в одиночной точности; для этого необходимо (но не всегда достаточно) привести все веса к соответствующему типу. Наследование от класса `nn.Module` позволяет сделать это одной командой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.weights.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = linear.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.weights.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = linear.float()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "linear.weights.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот что pytorch из коробки делать не позволяет, так это узнать, на каком устройстве лежит наша модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = linear.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.weights.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем собственно применить нашу модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(32, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = linear(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(32, 9)\n",
    "y = linear(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Рутина: все остальное"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1. Оптимизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(linear.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.param_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2. Лосс"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно написать самому:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(y_true, y_pred):\n",
    "    return ((y_true - y_pred) ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys_true = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_pred = torch.randn_like(ys_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss(ys_true, ys_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно использовать готовые:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import mse_loss as torch_mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_mse_loss(ys_true, ys_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3. Рутина обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание:** Дописать функцию для обучения.\n",
    "* Получение предсказаний моделью для объектов из батча\n",
    "* Подсчет лосса\n",
    "* Обновление весов по вызова backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, loss_fn, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    losses = []\n",
    "    for batch in dataloader:\n",
    "        xs, ys_true = batch\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        # ys_pred = ...\n",
    "        # loss = ...\n",
    "        # ...\n",
    "        # ...\n",
    "        \n",
    "        # END OF YOUR CODE\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "    \n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На валидации будем еще и сохранять результат предсказаний - для визуализации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_epoch(model, dataloader, loss_fn):\n",
    "    model.eval()\n",
    "    \n",
    "    losses = []\n",
    "    preds = []\n",
    "    for batch in dataloader:\n",
    "        xs, ys_true = batch\n",
    "        with torch.no_grad():\n",
    "            ys_pred = model(xs)\n",
    "        \n",
    "        loss = loss_fn(ys_pred, ys_true)        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        preds.append(ys_pred.numpy())\n",
    "    \n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    return np.mean(losses), preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Учим"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с обучения 1 полносвязного слоя, по сути - аппроксимируем данные прямой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 128\n",
    "lr = 8e-4\n",
    "batch_size = 8\n",
    "\n",
    "train_size = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.random.uniform(-3, 3, size=num_samples)\n",
    "ys_clean = _a * xs ** 2 + _b * xs + _c\n",
    "ys_noise = np.random.normal(0, 1, size=len(ys_clean))\n",
    "ys = ys_clean + ys_noise\n",
    "\n",
    "train_dataset = CustomDataset(xs[:train_size], ys[:train_size])\n",
    "val_dataset = CustomDataset(xs[train_size:], ys[train_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    collate_fn=train_dataset.collate_fn, \n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    collate_fn=train_dataset.collate_fn, \n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomLinear(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "val_losses = []\n",
    "val_preds = []\n",
    "for epoch in tqdm.trange(num_epochs):\n",
    "    loss = train_epoch(model, train_dataloader, optimizer, loss_fn, epoch)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    val_loss, preds = val_epoch(model, val_dataloader, loss_fn)\n",
    "    val_losses.append(val_loss)\n",
    "    val_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_losses)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"val loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(xs[train_size:], ys[train_size:], label=\"true\")\n",
    "plt.scatter(xs[train_size:], val_preds[-1], label=\"fc_1layer\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_1layer_train_losses = losses\n",
    "fc_1layer_val_losses = val_losses\n",
    "fc_1layer_preds = preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Stack more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Sequential\n",
    "from torch.nn import ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: соберите сеть из двух полносвязных слоев размерами (1, 4) и (4, 1); добавьте между слоями нелинейность ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "layers = ...\n",
    "model = ...\n",
    "\n",
    "# END OF YOUR CODE\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "val_losses = []\n",
    "val_preds = []\n",
    "for epoch in tqdm.trange(num_epochs):\n",
    "    loss = train_epoch(model, train_dataloader, optimizer, loss_fn, epoch)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    val_loss, preds = val_epoch(model, val_dataloader, loss_fn)\n",
    "    val_losses.append(val_loss)\n",
    "    val_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses, label=\"fc_2layers_4h\")\n",
    "plt.plot(fc_1layer_train_losses, label=\"fc_1layer\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_losses, label=\"fc_2layers_4h\")\n",
    "plt.plot(fc_1layer_val_losses, label=\"fc_1layer\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"val loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(xs[train_size:], ys[train_size:], label=\"true\")\n",
    "plt.scatter(xs[train_size:], val_preds[-1], label=\"fc_2layer_4h\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_2layer_4h_train_losses = losses\n",
    "fc_2layer_4h_val_losses = val_losses\n",
    "fc_2layer_4h_preds = preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим нейронов в скрытый слой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "    CustomLinear(1, 8),\n",
    "    ReLU(inplace=True),\n",
    "    CustomLinear(8, 1)\n",
    "]\n",
    "\n",
    "model = Sequential(*layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "val_losses = []\n",
    "for epoch in tqdm.trange(num_epochs):\n",
    "    loss = train_epoch(model, train_dataloader, optimizer, loss_fn, epoch)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    val_loss, preds = val_epoch(model, val_dataloader, loss_fn)\n",
    "    val_losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses, label=\"fc_2layer_8h\")\n",
    "plt.plot(fc_2layer_4h_train_losses, label=\"fc_2layer_4h\")\n",
    "plt.plot(fc_1layer_train_losses, label=\"fc_1layer\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_losses, label=\"fc_2layer_8h\")\n",
    "plt.plot(fc_2layer_4h_val_losses, label=\"fc_2layer_4h\")\n",
    "plt.plot(fc_1layer_val_losses, label=\"fc_1layer\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"val loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(xs[train_size:], ys[train_size:], label=\"true\")\n",
    "plt.scatter(xs[train_size:], preds, label=\"fc_2layer_8h\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видимо, что наша модель ведет себя как кусочно-линейная функция. Любопытные визуализации на эту тему можно найти, например, [здесь](http://neuralnetworksanddeeplearning.com/chap4.htmlhttp://neuralnetworksanddeeplearning.com/chap4.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пища для размышлений:** данные были сгенерированы с использованием всего лишь трех неизвестных параметров (a, b, c). Они полностью, не считая случайного шума, определяют поведение целевой функции. Нам же потребовалось значительно больше параметров (сколько, кстати?), чтобы кое-как аппроксимировать данные с помощью полносвязной сети. Почему это так? Можно ли с этим что-то сделать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обученные веса модели хорошо бы уметь сохранять и загружать для дальнейшего использования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В Pytorch сохранение и загрузка весов выполняется через `state_dict` модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fn = \"./state_dict.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_fn, \"wb\") as fp:\n",
    "    torch.save(model.state_dict(), fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(CustomLinear(1, 8), ReLU(inplace=True), CustomLinear(8, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_fn, \"rb\") as fp:\n",
    "    state_dict = torch.load(fp, map_location=\"cpu\")\n",
    "state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помимо непосредственно весов, бывает полезно сохранить и состояние других объектов: например, оптимизатора (чтобы продолжить обучении с той же точки):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, output_fn):\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict()\n",
    "    }\n",
    "    \n",
    "    with open(output_fn, \"wb\") as fp:\n",
    "        torch.save(checkpoint, output_fn)\n",
    "        \n",
    "def load_checkpoint(checkpoint_fn, model, optimizer):\n",
    "    with open(checkpoint_fn, \"rb\") as fp:\n",
    "        checkpoint = torch.load(fp, map_location=\"cpu\")\n",
    "    \n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "optimizer.param_groups[0][\"lr\"] = 1e-10\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_fn = \"./checkpoint.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint(model, optimizer, checkpoint_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_checkpoint(checkpoint_fn, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Пример с картинками: MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучения на MNIST в курсе DL почти не избежать..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST - это ставший классикой датасет с изображениями рукописных цифр. На нем мы построим минимальный пример работы с изображениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/myleott/mnist_png/raw/master/mnist_png.tar.gz\n",
    "# !tar -xzf mnist_png.tar.gz\n",
    "!ls mnist_png/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отличие от датасета, рассмотренного в начале семинара, здесь мы будем передавать не непосредственно данные, а путь до папки с файлами; причем структуру мы считаем известной (`split/digit/*.png`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir):\n",
    "        self.images_filenames = []\n",
    "        self.class_labels = []\n",
    "        for class_label in os.listdir(root_dir):\n",
    "            for image_basename in os.listdir(os.path.join(root_dir, class_label)):\n",
    "                if not image_basename.endswith(\".png\"):\n",
    "                    continue\n",
    "                image_filename = os.path.join(root_dir, class_label, image_basename)\n",
    "                self.images_filenames.append(image_filename)\n",
    "                self.class_labels.append(int(class_label))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images_filenames)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        image = cv2.imread(self.images_filenames[i], cv2.IMREAD_GRAYSCALE)\n",
    "        label = self.class_labels[i]\n",
    "        return image, label\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate_fn(items):\n",
    "        images = []\n",
    "        labels = []\n",
    "        for image, label in items:\n",
    "            image = image / 255.\n",
    "            images.append(image.ravel())\n",
    "            labels.append(label)\n",
    "        return torch.tensor(images).float(), torch.tensor(labels).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNISTDataset(root_dir=\"mnist_png/training\")\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на сами данные из датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_dataset[0]\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image[:14, -14:], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомогательная функция для массовой визуализации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images_with_captions(images, captions=None, ncol=8):\n",
    "    nrow = len(images) // ncol\n",
    "    \n",
    "    plt.figure(figsize=(16, 16 * nrow // ncol))\n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(nrow, ncol, i + 1)\n",
    "        plt.imshow(images[i], cmap=\"gray\")\n",
    "        if captions is not None:\n",
    "            plt.title(captions[i])\n",
    "        plt.grid(False)\n",
    "        plt.axis(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indices = np.random.choice(len(train_dataset), size=64, replace=False)\n",
    "\n",
    "sample_images = []\n",
    "sample_captions = []\n",
    "for i in sample_indices:\n",
    "    image, label = train_dataset[i]\n",
    "    sample_images.append(image)\n",
    "    sample_captions.append(f\"gt: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_with_captions(sample_images, sample_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зарядим теперь обучение сети чуть глубже (3 слоя), да еще и с BatchNorm1d:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "lr = 3e-4\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "# device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=train_dataset.collate_fn\n",
    ")\n",
    "\n",
    "val_dataset = MNISTDataset(root_dir=\"mnist_png/testing/\")\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=train_dataset.collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import BatchNorm1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    CustomLinear(28*28, 512),\n",
    "    ReLU(inplace=True),\n",
    "    BatchNorm1d(512),\n",
    "    CustomLinear(512, 1024),\n",
    "    ReLU(inplace=True),\n",
    "    BatchNorm1d(1024),\n",
    "    CustomLinear(1024, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лосс возьмем готовый, свой напишете дома:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "loss_fn = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции для обучения / валидации возьмем те же, что и раньше - пока сгодятся:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "val_losses = []\n",
    "val_preds = []\n",
    "for epoch in tqdm.trange(num_epochs):\n",
    "    loss = train_epoch(model, train_dataloader, optimizer, loss_fn, epoch)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    val_loss, preds = val_epoch(model, val_dataloader, loss_fn)\n",
    "    val_losses.append(val_loss)\n",
    "    val_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"xEntLoss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соберем все предсказания / gt-лейблы, чтобы посчитать метрику Accuracy и сделать визуализацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_labels = []\n",
    "for val_pred in val_preds[-1]:\n",
    "    pred_label = np.argmax(val_pred)\n",
    "    val_pred_labels.append(pred_label)\n",
    "val_pred_labels = np.asarray(val_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = []\n",
    "for image, label in val_dataset:\n",
    "    val_labels.append(label)\n",
    "val_labels = np.asarray(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = (val_pred_labels == val_labels).mean()\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indices = np.random.choice(len(val_dataset), size=64, replace=False)\n",
    "\n",
    "sample_images = []\n",
    "sample_captions = []\n",
    "for i in sample_indices:\n",
    "    image, label = val_dataset[i]\n",
    "    pred_label = val_pred_labels[i]\n",
    "    sample_images.append(image)\n",
    "    sample_captions.append(f\"gt: {label} | pred: {pred_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_with_captions(sample_images, sample_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем отдельно отрисовать те примеры из валидации, на которых модель ошибается:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indices = np.random.choice(np.where(val_labels != val_pred_labels)[0], size=64, replace=False)\n",
    "\n",
    "sample_images = []\n",
    "sample_captions = []\n",
    "for i in sample_indices:\n",
    "    image, label = val_dataset[i]\n",
    "    pred_label = val_pred_labels[i]\n",
    "    sample_images.append(image)\n",
    "    sample_captions.append(f\"gt: {label} | pred: {pred_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_with_captions(sample_images, sample_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLPPlL6Sj39B"
   },
   "source": [
    "## Итоги\n",
    "\n",
    "* Узнали, какие есть базовые сущности в Pytorch для обучения нейросетей\n",
    "* Реализовали собственные классы датасета и модели\n",
    "* Написали собственную функции активации и даже `backward()` для нее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В следующий раз: \n",
    "* Свертки и сверточные сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNmX+t/f/S/AKgjzKepbc+b",
   "name": "Семинар 03. NN with PyTorch(Classwork).ipynb",
   "provenance": [
    {
     "file_id": "1VR8KlyfZEYXayf1AGBMwf2TB_k8HwedF",
     "timestamp": 1632410238934
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
