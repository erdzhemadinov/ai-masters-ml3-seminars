{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ef74f92-158b-46c6-86ea-96200ff596e2",
   "metadata": {
    "id": "0ef74f92-158b-46c6-86ea-96200ff596e2"
   },
   "source": [
    "# 04. Свертки & сети"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dcba1f-7fb6-4c63-b54f-3c9fbcc5437a",
   "metadata": {
    "id": "e5dcba1f-7fb6-4c63-b54f-3c9fbcc5437a"
   },
   "source": [
    "## План\n",
    "0. Полносвязная сеть на MNIST (с прошлого семинара)\n",
    "1. (DIY) Свертка\n",
    "2. Сверточный слой\n",
    "3. Сборка CNN\n",
    "4. Обучение и результаты\n",
    "5. (bonus) Различные способы организации слоев в pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3c6199-b42b-474f-aac6-9516456f7f02",
   "metadata": {
    "id": "8c3c6199-b42b-474f-aac6-9516456f7f02",
    "tags": []
   },
   "source": [
    "## 0. Пример с картинками: MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e7837d-5c9c-429e-8f9e-2868db0cda4b",
   "metadata": {
    "id": "e8e7837d-5c9c-429e-8f9e-2868db0cda4b"
   },
   "source": [
    "Обучения на MNIST в курсе DL почти не избежать..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ff4d70-4ad5-42b8-8e21-db288eceee5f",
   "metadata": {
    "id": "f9ff4d70-4ad5-42b8-8e21-db288eceee5f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe773df-1749-4de9-af89-64dbffb9806e",
   "metadata": {
    "id": "afe773df-1749-4de9-af89-64dbffb9806e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c0d2c-cf99-4308-9f06-ef13989c5249",
   "metadata": {
    "id": "1b3c0d2c-cf99-4308-9f06-ef13989c5249"
   },
   "outputs": [],
   "source": [
    "#!pip install opencv-python\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddaef1f-cba7-44b6-91d7-20953df96317",
   "metadata": {
    "id": "eddaef1f-cba7-44b6-91d7-20953df96317"
   },
   "source": [
    "MNIST - это ставший классикой датасет с изображениями рукописных цифр. На нем мы построим минимальный пример работы с изображениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac92f18a-4720-4cf3-ab9e-43bd492ba6fb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ac92f18a-4720-4cf3-ab9e-43bd492ba6fb",
    "outputId": "5a82be2f-5c66-4a56-c3d7-01a76fe8dcd0"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/myleott/mnist_png/raw/master/mnist_png.tar.gz\n",
    "!tar -xzf mnist_png.tar.gz\n",
    "!ls mnist_png/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994278d0-50f5-414c-a7db-a42664c4f6fd",
   "metadata": {
    "id": "994278d0-50f5-414c-a7db-a42664c4f6fd"
   },
   "source": [
    "В отличие от датасета, рассмотренного на прошлом семинаре, здесь мы будем передавать не непосредственно данные, а путь до папки с файлами; причем структуру мы считаем известной (`split/digit/*.png`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406009f8-63ee-4e87-b776-6c68c4abb677",
   "metadata": {
    "id": "406009f8-63ee-4e87-b776-6c68c4abb677"
   },
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir):\n",
    "        self.images_filenames = []\n",
    "        self.class_labels = []\n",
    "        for class_label in os.listdir(root_dir):\n",
    "            for image_basename in os.listdir(os.path.join(root_dir, class_label)):\n",
    "                if not image_basename.endswith(\".png\"):\n",
    "                    continue\n",
    "                image_filename = os.path.join(root_dir, class_label, image_basename)\n",
    "                self.images_filenames.append(image_filename)\n",
    "                self.class_labels.append(int(class_label))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images_filenames)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        image = cv2.imread(self.images_filenames[i], cv2.IMREAD_GRAYSCALE)\n",
    "        label = self.class_labels[i]\n",
    "        return image, label\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate_fn(items):\n",
    "        images = np.zeros((len(items), 28*28), dtype=np.float32)\n",
    "        labels = np.zeros(len(items), dtype=np.uint8)\n",
    "        for i, (image, label) in enumerate(items):\n",
    "            image = image / 255.\n",
    "            images[i] = image.ravel()\n",
    "            labels[i] = label\n",
    "        return torch.tensor(images).float(), torch.tensor(labels).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3946b00e-012b-48ed-973d-a531fc224e6b",
   "metadata": {
    "id": "3946b00e-012b-48ed-973d-a531fc224e6b"
   },
   "source": [
    "**NB:** можно было сделать парсинг файлов на диске через `glob.glob()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710c3c1f-2e11-4f15-9f43-35222add2626",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "710c3c1f-2e11-4f15-9f43-35222add2626",
    "outputId": "94e24658-30e9-4428-bc50-a7845cbde5f3"
   },
   "outputs": [],
   "source": [
    "train_dataset = MNISTDataset(root_dir=\"mnist_png/training\")\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2e15ff-b5d8-4d5e-8753-1cd9585f31c1",
   "metadata": {
    "id": "6b2e15ff-b5d8-4d5e-8753-1cd9585f31c1"
   },
   "source": [
    "Посмотрим на сами данные из датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9c1660-45b0-45d4-aff1-d945fd8249a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "eb9c1660-45b0-45d4-aff1-d945fd8249a7",
    "outputId": "d45a55b1-2d8a-4ad0-8cec-4f44b6fb4a66"
   },
   "outputs": [],
   "source": [
    "image, label = train_dataset[0]\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8c42c8-1fcb-4018-b137-681bfe954c0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "bc8c42c8-1fcb-4018-b137-681bfe954c0d",
    "outputId": "38db916f-fefa-43f2-9f3b-cd52182c7498"
   },
   "outputs": [],
   "source": [
    "plt.imshow(image[:14, -14:], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fda890-07b2-46b0-9862-5c5c9fd5dee4",
   "metadata": {
    "id": "94fda890-07b2-46b0-9862-5c5c9fd5dee4"
   },
   "source": [
    "Вспомогательная функция для массовой визуализации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130d59a3-69ab-4454-aadd-5db47456314a",
   "metadata": {
    "id": "130d59a3-69ab-4454-aadd-5db47456314a"
   },
   "outputs": [],
   "source": [
    "def show_images_with_captions(images, captions=None, ncol=8):\n",
    "    nrow = len(images) // ncol\n",
    "    \n",
    "    plt.figure(figsize=(16, 16 * nrow // ncol))\n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(nrow, ncol, i + 1)\n",
    "        plt.imshow(images[i], cmap=\"gray\")\n",
    "        if captions is not None:\n",
    "            plt.title(captions[i])\n",
    "        plt.grid(False)\n",
    "        plt.axis(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c62f15-81c6-4379-89f3-d4eae5d51f1d",
   "metadata": {
    "id": "29c62f15-81c6-4379-89f3-d4eae5d51f1d"
   },
   "outputs": [],
   "source": [
    "sample_indices = np.random.choice(len(train_dataset), size=64, replace=False)\n",
    "\n",
    "sample_images = []\n",
    "sample_captions = []\n",
    "for i in sample_indices:\n",
    "    image, label = train_dataset[i]\n",
    "    sample_images.append(image)\n",
    "    sample_captions.append(f\"gt: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b626d05b-c50c-43cf-9b8f-62a41302bc0f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "b626d05b-c50c-43cf-9b8f-62a41302bc0f",
    "outputId": "a17261ee-39b5-42a9-98c3-e03e705337cf"
   },
   "outputs": [],
   "source": [
    "show_images_with_captions(sample_images, sample_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31570486-3bd2-4404-b82d-1fe0b3a8da6f",
   "metadata": {
    "id": "31570486-3bd2-4404-b82d-1fe0b3a8da6f"
   },
   "source": [
    "Зарядим теперь обучение сети чуть глубже (3 слоя), да еще и с BatchNorm1d:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e347359-6bc9-4911-9001-6c45943bba75",
   "metadata": {
    "id": "1e347359-6bc9-4911-9001-6c45943bba75"
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "lr = 3e-4\n",
    "\n",
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521d0c4f-e33e-4a0e-bb40-47013c51e3a4",
   "metadata": {
    "id": "521d0c4f-e33e-4a0e-bb40-47013c51e3a4"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=train_dataset.collate_fn\n",
    ")\n",
    "\n",
    "val_dataset = MNISTDataset(root_dir=\"mnist_png/testing/\")\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=train_dataset.collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043f682a-43de-4ba6-bc4d-f276d8b5b5d2",
   "metadata": {
    "id": "043f682a-43de-4ba6-bc4d-f276d8b5b5d2"
   },
   "outputs": [],
   "source": [
    "from torch.nn import Sequential, Linear, BatchNorm1d, ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37b91a7-718d-43d1-b031-6b2118cc1097",
   "metadata": {
    "id": "e37b91a7-718d-43d1-b031-6b2118cc1097"
   },
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    Linear(28*28, 512),\n",
    "    ReLU(inplace=True),\n",
    "    BatchNorm1d(512),\n",
    "    Linear(512, 1024),\n",
    "    ReLU(inplace=True),\n",
    "    BatchNorm1d(1024),\n",
    "    Linear(1024, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8724aa1a-4d68-4d63-814f-62b7abbc4192",
   "metadata": {
    "id": "8724aa1a-4d68-4d63-814f-62b7abbc4192"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a4e1e6-a0c3-439d-870a-3b53e88f54cf",
   "metadata": {
    "id": "e3a4e1e6-a0c3-439d-870a-3b53e88f54cf"
   },
   "source": [
    "Лосс:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5411ba2-a2a2-4650-91ef-fada22986fa9",
   "metadata": {
    "id": "e5411ba2-a2a2-4650-91ef-fada22986fa9"
   },
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "loss_fn = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b88252-9111-4d09-a64e-ab3ad487406c",
   "metadata": {
    "id": "c2b88252-9111-4d09-a64e-ab3ad487406c"
   },
   "source": [
    "Функции для обучения / валидации:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e468b2ce-0943-480a-b7e4-557f9fc5c311",
   "metadata": {
    "id": "e468b2ce-0943-480a-b7e4-557f9fc5c311"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, loss_fn, epoch, device=device):\n",
    "    model.train()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    losses = []\n",
    "    for batch in dataloader:\n",
    "        xs, ys_true = batch\n",
    "                \n",
    "        ys_pred = model(xs.to(device))\n",
    "        loss = loss_fn(ys_pred, ys_true.to(device))\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        losses.append(loss.cpu().item())\n",
    "    \n",
    "    return np.mean(losses)\n",
    "\n",
    "\n",
    "def val_epoch(model, dataloader, loss_fn, device=device):\n",
    "    model.eval()\n",
    "    \n",
    "    losses = []\n",
    "    preds = []\n",
    "    for batch in dataloader:\n",
    "        xs, ys_true = batch\n",
    "        with torch.no_grad():\n",
    "            ys_pred = model(xs.to(device))\n",
    "        \n",
    "        loss = loss_fn(ys_pred, ys_true.to(device))        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        preds.append(ys_pred.cpu().numpy())\n",
    "    \n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    return np.mean(losses), preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b563516-d7c7-4db5-8674-fd5af284d8c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b563516-d7c7-4db5-8674-fd5af284d8c1",
    "outputId": "f1a4b9cc-640d-4361-abb9-da3e8c73ef83"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "val_losses = []\n",
    "val_preds = []\n",
    "for epoch in tqdm.trange(num_epochs):\n",
    "    loss = train_epoch(model, train_dataloader, optimizer, loss_fn, epoch, device)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    val_loss, preds = val_epoch(model, val_dataloader, loss_fn)\n",
    "    val_losses.append(val_loss)\n",
    "    val_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120498fe-3a27-42a2-9979-fac6325cfba8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "120498fe-3a27-42a2-9979-fac6325cfba8",
    "outputId": "793d8f57-9cf1-43a5-9ca9-0c838b42643d"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"xEntLoss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb449141-cec5-4449-bbf0-aeb51c2c0edc",
   "metadata": {
    "id": "bb449141-cec5-4449-bbf0-aeb51c2c0edc"
   },
   "source": [
    "Соберем все предсказания / gt-лейблы, чтобы посчитать метрику Accuracy и сделать визуализацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc778c1d-cc64-4535-804c-e5707e283ea1",
   "metadata": {
    "id": "dc778c1d-cc64-4535-804c-e5707e283ea1"
   },
   "outputs": [],
   "source": [
    "val_pred_labels = []\n",
    "for val_pred in val_preds[-1]:\n",
    "    pred_label = np.argmax(val_pred)\n",
    "    val_pred_labels.append(pred_label)\n",
    "val_pred_labels = np.asarray(val_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e044beca-f281-449c-8888-eff7b3d21a2d",
   "metadata": {
    "id": "e044beca-f281-449c-8888-eff7b3d21a2d"
   },
   "outputs": [],
   "source": [
    "val_labels = []\n",
    "for image, label in val_dataset:\n",
    "    val_labels.append(label)\n",
    "val_labels = np.asarray(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da19a650-be8f-4380-8483-f6beb183367e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "da19a650-be8f-4380-8483-f6beb183367e",
    "outputId": "9fe17cd2-ccc6-4562-c7d8-91ebdd4195ba"
   },
   "outputs": [],
   "source": [
    "acc = (val_pred_labels == val_labels).mean()\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p7Zy5v5TGjUy",
   "metadata": {
    "id": "p7Zy5v5TGjUy"
   },
   "source": [
    "Посмотрим, как соотносятся истинные лейблы и предсказанные моделью:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7052e1c7-6766-4e35-89d0-99e6e1a8ae9b",
   "metadata": {
    "id": "7052e1c7-6766-4e35-89d0-99e6e1a8ae9b"
   },
   "outputs": [],
   "source": [
    "sample_indices = np.random.choice(len(val_dataset), size=64, replace=False)\n",
    "\n",
    "sample_images = []\n",
    "sample_captions = []\n",
    "for i in sample_indices:\n",
    "    image, label = val_dataset[i]\n",
    "    pred_label = val_pred_labels[i]\n",
    "    sample_images.append(image)\n",
    "    sample_captions.append(f\"gt: {label} | pred: {pred_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e82fb4-f8b6-4000-9747-90623f81e1ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "e8e82fb4-f8b6-4000-9747-90623f81e1ac",
    "outputId": "3e2dd7b6-dfd4-4191-9935-d96738e8343b"
   },
   "outputs": [],
   "source": [
    "show_images_with_captions(sample_images, sample_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb934f7-8f41-4ce3-be19-fbfd839c09de",
   "metadata": {
    "id": "6bb934f7-8f41-4ce3-be19-fbfd839c09de"
   },
   "source": [
    "Можем отдельно отрисовать те примеры из валидации, на которых модель ошибается:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a27a24-ac32-4f32-bc19-c1345ed34971",
   "metadata": {
    "id": "b0a27a24-ac32-4f32-bc19-c1345ed34971"
   },
   "outputs": [],
   "source": [
    "sample_indices = np.random.choice(np.where(val_labels != val_pred_labels)[0], size=64, replace=False)\n",
    "\n",
    "sample_images = []\n",
    "sample_captions = []\n",
    "for i in sample_indices:\n",
    "    image, label = val_dataset[i]\n",
    "    pred_label = val_pred_labels[i]\n",
    "    sample_images.append(image)\n",
    "    sample_captions.append(f\"gt: {label} | pred: {pred_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58c2366-986f-4878-a062-dc3db6a56010",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "c58c2366-986f-4878-a062-dc3db6a56010",
    "outputId": "e512ce00-4d97-4caa-a313-d0eec6a6f21f"
   },
   "outputs": [],
   "source": [
    "show_images_with_captions(sample_images, sample_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45867dc7-21ff-43b9-b348-5b7cc14c25ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45867dc7-21ff-43b9-b348-5b7cc14c25ba",
    "outputId": "9b0793bb-2b51-440b-c796-d87e12f7ab40"
   },
   "outputs": [],
   "source": [
    "print((val_labels != val_pred_labels).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87667ec-95fd-402c-8e42-a4a979b2b0b6",
   "metadata": {
    "id": "c87667ec-95fd-402c-8e42-a4a979b2b0b6",
    "tags": []
   },
   "source": [
    "## 1. Свертка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5a7964-8497-4892-a2f2-23f68b66c7c8",
   "metadata": {
    "id": "dc5a7964-8497-4892-a2f2-23f68b66c7c8",
    "tags": []
   },
   "source": [
    "### 1.1. (DIY) Одномерная свертка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VIXJve62GwL2",
   "metadata": {
    "id": "VIXJve62GwL2"
   },
   "source": [
    "В этом блоке предлагается самостоятельно реализовать механизм одномерной свертки с поддержкой добавления паддинга."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87eaff2-aa57-413c-930f-8a27c3916328",
   "metadata": {
    "id": "e87eaff2-aa57-413c-930f-8a27c3916328"
   },
   "source": [
    "**Задача**: реализовать функцию для добавления паддингов тремя способами:\n",
    "* zero\n",
    "* replicate\n",
    "* reflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18b8a0b-cd53-4f07-9668-fd1258c0197b",
   "metadata": {
    "id": "f18b8a0b-cd53-4f07-9668-fd1258c0197b"
   },
   "outputs": [],
   "source": [
    "def pad_1d(signal, size, kind):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # signal_padded = ...\n",
    "    \n",
    "    # if kind == \"zero\":\n",
    "        # pass\n",
    "    # elif kind == \"replicate\":\n",
    "        # pass\n",
    "    # elif kind == \"reflect\":\n",
    "        # pass\n",
    "    # else:\n",
    "        # raise NotImplementedError(kind)\n",
    "        \n",
    "    # END OF YOUR CODE\n",
    "    \n",
    "    return signal_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff06a4ce-6c92-4247-9944-3f35d8cb4079",
   "metadata": {
    "id": "ff06a4ce-6c92-4247-9944-3f35d8cb4079",
    "outputId": "aa0a0cf3-18f1-404f-bf7a-548b81dd5683"
   },
   "outputs": [],
   "source": [
    "signal = np.arange(10)\n",
    "signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72efde7-713f-46a2-9497-5c9d57e74ad1",
   "metadata": {
    "id": "f72efde7-713f-46a2-9497-5c9d57e74ad1"
   },
   "outputs": [],
   "source": [
    "np.testing.assert_array_equal(pad_1d(signal, 2, \"zero\"), np.array([0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d672939c-37fe-4102-8d55-2638b48c4490",
   "metadata": {
    "id": "d672939c-37fe-4102-8d55-2638b48c4490"
   },
   "outputs": [],
   "source": [
    "np.testing.assert_array_equal(pad_1d(signal, 2, \"replicate\"), np.array([0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 9, 9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18c8e19-5092-42ce-8fef-160c28d777ac",
   "metadata": {
    "id": "a18c8e19-5092-42ce-8fef-160c28d777ac"
   },
   "outputs": [],
   "source": [
    "np.testing.assert_array_equal(pad_1d(signal, 2, \"reflect\"), np.array([2, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 8, 7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6058005-4bf0-4981-bcd3-c5818f18f088",
   "metadata": {
    "id": "e6058005-4bf0-4981-bcd3-c5818f18f088"
   },
   "outputs": [],
   "source": [
    "np.testing.assert_array_equal(pad_1d(signal, 0, \"zero\"), np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe97998-c26e-4319-bc26-03862b315002",
   "metadata": {
    "id": "cfe97998-c26e-4319-bc26-03862b315002"
   },
   "source": [
    "**Задача**: реализовать (брутфорс) функцию вычисления свертки в одномерном случае с предварительным паддингом. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509c888d-394b-4703-bdcf-96cbe09fd6f4",
   "metadata": {
    "id": "509c888d-394b-4703-bdcf-96cbe09fd6f4"
   },
   "outputs": [],
   "source": [
    "def convolve_1d(signal, kernel, pad_size, pad_kind):\n",
    "    \n",
    "    signal_padded = pad_1d(signal, pad_size, pad_kind)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # signal_padded_convolved = ...\n",
    "    \n",
    "    # END OF YOUR CODE\n",
    "    \n",
    "    return signal_padded_convolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f53819-0a1d-4ff1-94bc-1b0ea4cc661e",
   "metadata": {
    "id": "40f53819-0a1d-4ff1-94bc-1b0ea4cc661e",
    "outputId": "adfc33f3-f6e3-4beb-89ce-b9c02c14b452"
   },
   "outputs": [],
   "source": [
    "signal = np.arange(10)\n",
    "signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f408c69a-135b-46c3-bdba-8f3f690b4af0",
   "metadata": {
    "id": "f408c69a-135b-46c3-bdba-8f3f690b4af0"
   },
   "outputs": [],
   "source": [
    "kernel = np.asarray([0, 0, 0])\n",
    "for pad_kind in (\"zero\", \"replicate\", \"reflect\"):\n",
    "    np.testing.assert_array_equal(convolve_1d(signal, kernel, 1, pad_kind), np.array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a1f7b7-5c9e-490d-89ce-3936cb73ae46",
   "metadata": {
    "id": "a1a1f7b7-5c9e-490d-89ce-3936cb73ae46"
   },
   "outputs": [],
   "source": [
    "kernel = np.asarray([0, 1, 0])\n",
    "for pad_kind in (\"zero\", \"replicate\", \"reflect\"):\n",
    "    np.testing.assert_array_equal(convolve_1d(signal, kernel, 1, pad_kind), np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36e62c1-7114-4875-81ea-b989c4c9fec3",
   "metadata": {
    "id": "b36e62c1-7114-4875-81ea-b989c4c9fec3"
   },
   "source": [
    "Можно использовать полученную функцию свертки для фильтрации шумного одномерного сигнала:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73138a5b-f6d5-4f63-8230-6a1745727495",
   "metadata": {
    "id": "73138a5b-f6d5-4f63-8230-6a1745727495"
   },
   "outputs": [],
   "source": [
    "eps = 1e-6\n",
    "def sinc(x):\n",
    "    return (np.sin(x) + eps) / (x + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4417256d-eaeb-4a47-92db-5354076dde47",
   "metadata": {
    "id": "4417256d-eaeb-4a47-92db-5354076dde47",
    "outputId": "e422b644-808d-43da-97cc-3f0b0b8c8d64"
   },
   "outputs": [],
   "source": [
    "xs = np.linspace(0, 20, 1000)\n",
    "signal = sinc(xs)\n",
    "noise = np.random.normal(size=len(signal)) / 10\n",
    "signal += noise\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(signal)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c53ccd-5a33-4493-bf25-f08d4849aa9b",
   "metadata": {
    "id": "42c53ccd-5a33-4493-bf25-f08d4849aa9b"
   },
   "outputs": [],
   "source": [
    "k = 51\n",
    "p = k // 2\n",
    "kernel = np.ones(k, dtype=np.float32) / k\n",
    "signal_smoothed = convolve_1d(signal, kernel, p, \"replicate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18544146-d7f7-41fe-85fa-9c17b7ee8109",
   "metadata": {
    "id": "18544146-d7f7-41fe-85fa-9c17b7ee8109",
    "outputId": "5d11f6e4-8a1a-43ba-b753-a3133f5d43f0"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(signal, label=\"signal\")\n",
    "plt.plot(signal_smoothed, label=f\"smoothed, k={k}\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9a2816-12fc-43b8-82e7-99db81c3fa56",
   "metadata": {
    "id": "fb9a2816-12fc-43b8-82e7-99db81c3fa56"
   },
   "source": [
    "### 1.2. Двумерная свертка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VH33m5ksHbgi",
   "metadata": {
    "id": "VH33m5ksHbgi"
   },
   "source": [
    "Для демонстраций нам понадобится какая-нибудь картинка, скачаем ее (или любую другую):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KSFL_YRo_ZlY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KSFL_YRo_ZlY",
    "outputId": "62d90cca-89fe-4f13-dd5c-98c07f9b1eca"
   },
   "outputs": [],
   "source": [
    "!wget -O volleyball.jpeg https://img.olympicchannel.com/images/image/private/t_social_share_thumb/f_auto/primary/bwkrhsijg1gb4oxwc7zf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pfkhHpJn_t1U",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pfkhHpJn_t1U",
    "outputId": "4831d648-a187-44e8-b99e-59f1b03aab16"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"volleyball.jpeg\", cv2.IMREAD_GRAYSCALE)\n",
    "image.shape, image.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jWIBC32g_yJw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "id": "jWIBC32g_yJw",
    "outputId": "bf38bc66-a0c1-4935-a969-ad26e5c3521f"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.imshow(image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JHmOk8txAiC5",
   "metadata": {
    "id": "JHmOk8txAiC5"
   },
   "outputs": [],
   "source": [
    "image = image.astype(np.float32) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eJDlul3UAmRc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "id": "eJDlul3UAmRc",
    "outputId": "f59284d5-6881-4033-ed30-0020b2feb1a5"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.imshow(image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2H1Q22XEHuez",
   "metadata": {
    "id": "2H1Q22XEHuez"
   },
   "source": [
    "В OpenCV есть реализованный механизм свертки с заданным ядром. Используем его для того, чтобы применить к картинке операцию сглаживания ([box filter](https://en.wikipedia.org/wiki/Box_blur)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6X2f0vA6_29u",
   "metadata": {
    "id": "6X2f0vA6_29u"
   },
   "outputs": [],
   "source": [
    "k = 1\n",
    "\n",
    "kernel = np.ones((k, k), dtype=np.float32) / (k * k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LnUsxsP9__yU",
   "metadata": {
    "id": "LnUsxsP9__yU"
   },
   "outputs": [],
   "source": [
    "image_conved = cv2.filter2D(image, -1, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_hqIWQlLAWoZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "id": "_hqIWQlLAWoZ",
    "outputId": "db6bbf01-75a0-45f7-a425-ae7b649984f2"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.imshow(image_conved, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a648df-a2b5-4cb8-9925-320a1fe5ed41",
   "metadata": {
    "id": "15a648df-a2b5-4cb8-9925-320a1fe5ed41"
   },
   "source": [
    "## 2. Сверточный слой"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e351db06-dbbe-45c7-abf6-5de4156d48db",
   "metadata": {
    "id": "e351db06-dbbe-45c7-abf6-5de4156d48db"
   },
   "source": [
    "OpenCV предоставляет функцию для свертки с заданным ядром. Но нам-то нужны обучаемые свертки!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca469f1-171f-48fa-9990-7b3bfd1e6b61",
   "metadata": {
    "id": "1ca469f1-171f-48fa-9990-7b3bfd1e6b61"
   },
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a95631-74ad-4f58-bd7b-cec31c4b0b7b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c7a95631-74ad-4f58-bd7b-cec31c4b0b7b",
    "outputId": "e76ad078-0af2-404b-eacd-a78f43a2e867"
   },
   "outputs": [],
   "source": [
    "conv = Conv2d(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    kernel_size=5,\n",
    "    padding=2\n",
    ")\n",
    "\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d014eb0a-041d-4dbd-a4c1-34731472ab38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d014eb0a-041d-4dbd-a4c1-34731472ab38",
    "outputId": "6b85b33f-f15c-495a-ed55-e9998da7c5b9"
   },
   "outputs": [],
   "source": [
    "conv.weight.shape  # == out_channels, in_channels, k, k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1842824-aa77-4465-84f5-dee1b238f7d0",
   "metadata": {
    "id": "d1842824-aa77-4465-84f5-dee1b238f7d0"
   },
   "source": [
    "Очень хочется применить этот слой к нашему изображению:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aed8c12-e25f-4aea-9ab6-0f6ed027b8a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "5aed8c12-e25f-4aea-9ab6-0f6ed027b8a4",
    "outputId": "e9cd7c43-0f37-47b5-d241-5814a5a29b5f"
   },
   "outputs": [],
   "source": [
    "conv(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rSLXH1yXIxSZ",
   "metadata": {
    "id": "rSLXH1yXIxSZ"
   },
   "source": [
    "Конечно же, чтобы пользоваться методами и классами из pytorch, надо обернуть данные в `torch.Tensor`.\n",
    "\n",
    "* **NB**: помним о том, что картинки размером (h, w, 1) `matplotlib` не поймет - либо \"серые\" (h, w), либо цветные (h, w, 3) (либо вообще (h, w, 4), если с прозрачностью)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f1b872-8f86-4ba0-868b-078923c8be50",
   "metadata": {
    "id": "d9f1b872-8f86-4ba0-868b-078923c8be50"
   },
   "outputs": [],
   "source": [
    "def image_to_tensor(image):\n",
    "    if image.ndim == 2:\n",
    "        image = image[:, :, np.newaxis]\n",
    "    if image.dtype == np.uint8:\n",
    "        image = image.astype(np.float32) / 255.\n",
    "        \n",
    "    tensor = torch.from_numpy(image)\n",
    "    tensor = tensor.permute(2, 0, 1).unsqueeze(0)\n",
    "    \n",
    "    return tensor\n",
    "\n",
    "\n",
    "def tensor_to_image(tensor):\n",
    "    image = tensor[0].permute(1, 2, 0).numpy()\n",
    "    if image.shape[-1] == 1:\n",
    "        image = image[:, :, 0]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1f550f-73ea-4f12-982f-b5996b3f5367",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a1f550f-73ea-4f12-982f-b5996b3f5367",
    "outputId": "5fbade70-4401-4457-aeb2-17814cea566d"
   },
   "outputs": [],
   "source": [
    "tensor = image_to_tensor(image)\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bc68c8-3163-444b-b891-1a7a387dfcc5",
   "metadata": {
    "id": "f5bc68c8-3163-444b-b891-1a7a387dfcc5"
   },
   "source": [
    "Теперь можно отправить тензор с нашим изображением в слой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c932e9-2988-4e90-9839-2fdcdeecc888",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50c932e9-2988-4e90-9839-2fdcdeecc888",
    "outputId": "af87d3e7-d115-4353-9cd1-f0d3ddf472d5"
   },
   "outputs": [],
   "source": [
    "y = conv(tensor)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1f28da-26d0-46a1-8321-5918d6060f32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fe1f28da-26d0-46a1-8321-5918d6060f32",
    "outputId": "9cb61a5f-e857-4691-8d4e-b3e8e6e949bb"
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f8b2d-b196-49a6-9a20-c4b8ba4a93c7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "id": "592f8b2d-b196-49a6-9a20-c4b8ba4a93c7",
    "outputId": "cd83d040-4b41-46f2-f70b-8e0744bba708"
   },
   "outputs": [],
   "source": [
    "image_conved = tensor_to_image(y.detach())\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.imshow(image_conved, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa7f774-1bce-49b2-8776-d16dd7dc95fc",
   "metadata": {
    "id": "4fa7f774-1bce-49b2-8776-d16dd7dc95fc",
    "tags": []
   },
   "source": [
    "Повторим наш трюк с реализацией `box filter`, но теперь \"записав\" наше ядро в веса сверточного слоя `Conv2d`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163afa83-499a-451f-933e-151bf56b76b1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "163afa83-499a-451f-933e-151bf56b76b1",
    "outputId": "395c0b88-f78d-4ee1-b2fa-47cefb7b2880"
   },
   "outputs": [],
   "source": [
    "k = 21\n",
    "p = k // 2\n",
    "\n",
    "conv = Conv2d(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    kernel_size=k,\n",
    "    padding=p\n",
    ")\n",
    "conv.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d00339a-fcce-44c1-be4f-06f0a7f577c8",
   "metadata": {
    "id": "2d00339a-fcce-44c1-be4f-06f0a7f577c8"
   },
   "outputs": [],
   "source": [
    "conv.weight[0] = 1 / (k * k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba31142-fef9-4e87-8b7d-ad20e37eb990",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "dba31142-fef9-4e87-8b7d-ad20e37eb990",
    "outputId": "e382cdff-faa1-4a5f-d794-71feb93e5471"
   },
   "outputs": [],
   "source": [
    "y = conv(tensor)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.imshow(tensor_to_image(y), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85383f8-9277-4259-8a36-c8b04b20e4b2",
   "metadata": {
    "id": "a85383f8-9277-4259-8a36-c8b04b20e4b2"
   },
   "source": [
    "Сверткам из 1 канала в 1 сыт не будешь - в современных моделях характерные глубины тензоров ~ 32, 64, 128, 256, 512, 1024, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b37653-32f1-4731-9a3c-fdf648d847e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06b37653-32f1-4731-9a3c-fdf648d847e0",
    "outputId": "841a652d-0123-428c-b654-60d80201cf0b"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"volleyball.jpeg\")\n",
    "image.shape, image.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0e16db-8e16-4784-b564-7e0e118575f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "id": "9e0e16db-8e16-4784-b564-7e0e118575f9",
    "outputId": "86554b1e-928a-4161-8084-2ff3141bc575"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "N3Im0Of2LAlj",
   "metadata": {
    "id": "N3Im0Of2LAlj"
   },
   "source": [
    "Неприятная вещь в `opencv` - по умолчанию изображения считываются в формате BGR вместо RGB. `matplotlib` к такому не готов и ждет изображения в RGB. Для этого придется делать конвертацию вручную:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9258564f-ad29-4a8b-b57e-08213c62a9c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "id": "9258564f-ad29-4a8b-b57e-08213c62a9c1",
    "outputId": "02da0889-eed3-457c-b057-b884ed6f71c6"
   },
   "outputs": [],
   "source": [
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67973ec4-5c26-4519-84e8-037ea11feccf",
   "metadata": {
    "id": "67973ec4-5c26-4519-84e8-037ea11feccf"
   },
   "source": [
    "[*BGR was a choice made for historical reasons and now we have to live with it. In other words, BGR is the horse’s ass in OpenCV.*](https://learnopencv.com/why-does-opencv-use-bgr-color-format/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d300ce87-fa1d-4a20-972b-ede04a495126",
   "metadata": {
    "id": "d300ce87-fa1d-4a20-972b-ede04a495126"
   },
   "source": [
    "Теперь у нашего тензора будет 3 канала, надо учесть это при создании сверточного слоя:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e40512-b539-4d17-909c-7c4c9c4a58d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9e40512-b539-4d17-909c-7c4c9c4a58d5",
    "outputId": "bde361c3-382e-4482-a644-d3e58e9b6c5a"
   },
   "outputs": [],
   "source": [
    "conv = Conv2d(\n",
    "    in_channels=3,\n",
    "    out_channels=16,\n",
    "    kernel_size=5,\n",
    "    padding=2\n",
    ")\n",
    "\n",
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c086231-8ac5-4255-ac70-595641e05321",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3c086231-8ac5-4255-ac70-595641e05321",
    "outputId": "97acef0d-23c1-4ca5-c45d-0b8abf8dd9f7"
   },
   "outputs": [],
   "source": [
    "conv.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c561402-831a-49ee-8d33-671e0d14c838",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8c561402-831a-49ee-8d33-671e0d14c838",
    "outputId": "41f29b3b-2f7e-4ee6-d185-1cd5c09e8868"
   },
   "outputs": [],
   "source": [
    "x = image_to_tensor(image)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Y1m9daXmLmHl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y1m9daXmLmHl",
    "outputId": "8be741c5-c64d-42a3-c406-af7662ab3e04"
   },
   "outputs": [],
   "source": [
    "y = conv(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6BYlrQ-OBneS",
   "metadata": {
    "id": "6BYlrQ-OBneS"
   },
   "source": [
    "**Задание**: реализуйте сверточный слой (со сверткой размера 1х1), который изменит порядок следования каналов в тензоре глубины 3 на противоположный."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1azpy3yQBpDZ",
   "metadata": {
    "id": "1azpy3yQBpDZ"
   },
   "outputs": [],
   "source": [
    "def create_channels_permutator():\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    # conv = \n",
    "\n",
    "    # END OF YOUR CODE\n",
    "\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VDNh9-cwCqvu",
   "metadata": {
    "id": "VDNh9-cwCqvu"
   },
   "outputs": [],
   "source": [
    "x = image_to_tensor(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Pscy7gWxCwNF",
   "metadata": {
    "id": "Pscy7gWxCwNF"
   },
   "outputs": [],
   "source": [
    "permutator = create_channels_permutator()\n",
    "with torch.no_grad():\n",
    "    x_permuted = permutator(x)\n",
    "\n",
    "for i in range(3):\n",
    "    np.testing.assert_array_equal(x[0, i].numpy(), x_permuted[0, -i-1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2q_3boIZEQN7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "id": "2q_3boIZEQN7",
    "outputId": "2a313380-c1b3-43d6-fda5-3431ebbadc90"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.imshow(tensor_to_image(x_permuted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41ca4ea-feb2-442f-950f-1c93382a8acf",
   "metadata": {
    "id": "f41ca4ea-feb2-442f-950f-1c93382a8acf"
   },
   "source": [
    "## 3. Сборка CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baef0e7-d96e-4874-aad4-53a4b30cec11",
   "metadata": {
    "id": "5baef0e7-d96e-4874-aad4-53a4b30cec11"
   },
   "source": [
    "Теперь, когда мы познакомились со сверточными слоями, пришла пора собрать нейросеть на их основе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1756a4bc-2a8f-45b3-a058-2645faed40c3",
   "metadata": {
    "id": "1756a4bc-2a8f-45b3-a058-2645faed40c3"
   },
   "outputs": [],
   "source": [
    "from torch.nn import Conv2d, MaxPool2d, AvgPool2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DYJ1Bz6JMEnr",
   "metadata": {
    "id": "DYJ1Bz6JMEnr"
   },
   "source": [
    "Кроме сверточных слоев нам пригодятся пулинги:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3df821d-e6f9-489f-9c66-22ef488bccb4",
   "metadata": {
    "id": "c3df821d-e6f9-489f-9c66-22ef488bccb4"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0251a002-d00d-437f-93c7-fade2a50f474",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0251a002-d00d-437f-93c7-fade2a50f474",
    "outputId": "a5b8942c-a259-4799-8ca6-2813c31fdc52"
   },
   "outputs": [],
   "source": [
    "max_pool2d = MaxPool2d((2, 2))\n",
    "max_pool2d(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177f0f3b-abcb-45ba-9297-07eb61e5d24f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "177f0f3b-abcb-45ba-9297-07eb61e5d24f",
    "outputId": "f72c75b6-5f16-4808-d026-a116f50888f6"
   },
   "outputs": [],
   "source": [
    "avg_pool2d = AvgPool2d((2, 2))\n",
    "avg_pool2d(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272d9cab-e776-4180-8ef4-d80067cbc2b6",
   "metadata": {
    "id": "272d9cab-e776-4180-8ef4-d80067cbc2b6"
   },
   "source": [
    "И еще два важных слоя:\n",
    "* `BatchNorm2d` для батч-нормализации\n",
    "* `Flatten` для \"вытягивания\" тензора в вектор (для финальной классификации)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43dcd4b-948e-43e7-ace9-9a8c95ef952b",
   "metadata": {
    "id": "b43dcd4b-948e-43e7-ace9-9a8c95ef952b"
   },
   "outputs": [],
   "source": [
    "from torch.nn import BatchNorm2d, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cTvas870MgaO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cTvas870MgaO",
    "outputId": "33f2b839-cf17-4789-9224-b22838ce84f1"
   },
   "outputs": [],
   "source": [
    "bn = BatchNorm2d(3)\n",
    "bn(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEFOK9ySMmdT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lEFOK9ySMmdT",
    "outputId": "46fa821e-f4b9-454f-c77b-0a6c86325130"
   },
   "outputs": [],
   "source": [
    "flatten = Flatten()\n",
    "flatten(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ng2JfVRaMvBE",
   "metadata": {
    "id": "Ng2JfVRaMvBE"
   },
   "source": [
    "Собираем (с параметрами для датасета MNIST):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b5dc42-2cf3-49a9-abf6-e9f2cf1c1222",
   "metadata": {
    "id": "f6b5dc42-2cf3-49a9-abf6-e9f2cf1c1222"
   },
   "outputs": [],
   "source": [
    "my_cnn = Sequential(            # b x 1 x 28 x 28\n",
    "    Conv2d(1, 8, (3, 3), 1, 1), # b x 8 x 28 x 28\n",
    "    BatchNorm2d(8),             # ...\n",
    "    ReLU(inplace=True),         # ...\n",
    "    MaxPool2d((2, 2)),          # b x 8 x 14 x 14\n",
    "\n",
    "    Conv2d(8, 32, (3, 3), 1, 1),# b x 32 x 14 x 14\n",
    "    BatchNorm2d(32),            # ...\n",
    "    ReLU(inplace=True),         # ...\n",
    "    MaxPool2d((2, 2)),          # b x 32 x 7 x 7\n",
    "\n",
    "    Conv2d(32, 64, (3, 3), 1, 1),   # b x 64 x 7 x 7\n",
    "    ReLU(inplace=True),         # ...\n",
    "\n",
    "    AvgPool2d((7, 7)),          # b x 64 x 1 x 1\n",
    "\n",
    "    Flatten(),                  # b x 64\n",
    "    Linear(64, 10)              # b x 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81807629-fab5-4733-9248-9f6903082124",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "81807629-fab5-4733-9248-9f6903082124",
    "outputId": "68d2a6e1-66fb-4ae2-8e84-12ec443d1c91"
   },
   "outputs": [],
   "source": [
    "my_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa4001d-0060-4c0f-a4ec-1d39fdaf2352",
   "metadata": {
    "id": "caa4001d-0060-4c0f-a4ec-1d39fdaf2352"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(4, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3aaa2b-3a7d-4903-8211-55ad7bd44946",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2f3aaa2b-3a7d-4903-8211-55ad7bd44946",
    "outputId": "5b42c038-5ea8-4757-f516-476ed1e1c8cf"
   },
   "outputs": [],
   "source": [
    "my_cnn(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9-xgLeMY5RS1",
   "metadata": {
    "id": "9-xgLeMY5RS1"
   },
   "source": [
    "## 4. Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f9e12c-7a73-44e8-9b7c-97aa17d3e2d0",
   "metadata": {
    "id": "06f9e12c-7a73-44e8-9b7c-97aa17d3e2d0"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(my_cnn.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2699d00d-4fea-47dd-8379-fe35ec53b751",
   "metadata": {
    "id": "2699d00d-4fea-47dd-8379-fe35ec53b751"
   },
   "source": [
    "Лосс:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6432dca-510b-4494-8fdf-bdc540e1b4be",
   "metadata": {
    "id": "d6432dca-510b-4494-8fdf-bdc540e1b4be"
   },
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "loss_fn = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Qma8Zht45hmv",
   "metadata": {
    "id": "Qma8Zht45hmv"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17e230f-85ea-4603-a262-18505f80f02b",
   "metadata": {
    "id": "e17e230f-85ea-4603-a262-18505f80f02b"
   },
   "outputs": [],
   "source": [
    "def collate_fn(items):\n",
    "    images = np.zeros((len(items), 1, 28, 28), dtype=np.float32)\n",
    "    labels = np.zeros(len(items), dtype=np.uint8)\n",
    "    for i, (image, label) in enumerate(items):\n",
    "        image = image / 255.\n",
    "        images[i] = image\n",
    "        labels[i] = label\n",
    "    return torch.tensor(images).float(), torch.tensor(labels).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5a1f8c-a350-447c-9d94-e4920317cc57",
   "metadata": {
    "id": "1c5a1f8c-a350-447c-9d94-e4920317cc57"
   },
   "outputs": [],
   "source": [
    "val_dataset = MNISTDataset(root_dir=\"mnist_png/training/\")\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_dataset = MNISTDataset(root_dir=\"mnist_png/testing/\")\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5622131d-19cd-49b4-abbb-e7758b2016f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5622131d-19cd-49b4-abbb-e7758b2016f4",
    "outputId": "1d7a7744-e8e5-40f0-e3ec-c8bb98104cea"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "val_losses = []\n",
    "val_preds = []\n",
    "for epoch in tqdm.trange(num_epochs):\n",
    "    loss = train_epoch(my_cnn, train_dataloader, optimizer, loss_fn, epoch, device)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    val_loss, preds = val_epoch(my_cnn, val_dataloader, loss_fn, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768bd0b5-2198-428f-a8b3-f9252d72ed46",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "768bd0b5-2198-428f-a8b3-f9252d72ed46",
    "outputId": "ff336d00-8912-4db9-d04a-caea425a3720"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(losses, label=\"train\")\n",
    "plt.plot(val_losses, label=\"val\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"xEntLoss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fdf518-384d-445d-af71-fbdb44dafd14",
   "metadata": {
    "id": "96fdf518-384d-445d-af71-fbdb44dafd14"
   },
   "outputs": [],
   "source": [
    "val_pred_labels = []\n",
    "for val_pred in val_preds[-1]:\n",
    "    pred_label = np.argmax(val_pred)\n",
    "    val_pred_labels.append(pred_label)\n",
    "val_pred_labels = np.asarray(val_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3cb378-fb06-4fbe-94de-e8f49911c55c",
   "metadata": {
    "id": "1b3cb378-fb06-4fbe-94de-e8f49911c55c"
   },
   "outputs": [],
   "source": [
    "val_labels = []\n",
    "for image, label in val_dataset:\n",
    "    val_labels.append(label)\n",
    "val_labels = np.asarray(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706b85b0-c100-4f3f-af49-6f6a04476c18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "706b85b0-c100-4f3f-af49-6f6a04476c18",
    "outputId": "28203d57-98da-4e20-995b-252caf89f962"
   },
   "outputs": [],
   "source": [
    "acc = (val_pred_labels == val_labels).mean()\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749c2edd-a366-4450-a725-ae01cc68f5dd",
   "metadata": {
    "id": "749c2edd-a366-4450-a725-ae01cc68f5dd"
   },
   "outputs": [],
   "source": [
    "sample_indices = np.random.choice(len(val_dataset), size=64, replace=False)\n",
    "\n",
    "sample_images = []\n",
    "sample_captions = []\n",
    "for i in sample_indices:\n",
    "    image, label = val_dataset[i]\n",
    "    pred_label = val_pred_labels[i]\n",
    "    sample_images.append(image)\n",
    "    sample_captions.append(f\"gt: {label} | pred: {pred_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf9fdfb-db5e-4e8d-ac3b-11d087e58fca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "6bf9fdfb-db5e-4e8d-ac3b-11d087e58fca",
    "outputId": "f85ca988-5a1e-4bbc-984f-e030521d37dc"
   },
   "outputs": [],
   "source": [
    "show_images_with_captions(sample_images, sample_captions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f2eb3c-85d2-4937-a811-7a4e83e225d2",
   "metadata": {
    "id": "f0f2eb3c-85d2-4937-a811-7a4e83e225d2"
   },
   "source": [
    "Можем отдельно отрисовать те примеры из валидации, на которых модель ошибается:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fff06c-9a08-4566-b141-553dd6f411dc",
   "metadata": {
    "id": "e3fff06c-9a08-4566-b141-553dd6f411dc"
   },
   "outputs": [],
   "source": [
    "sample_indices = np.random.choice(np.where(val_labels != val_pred_labels)[0], size=64, replace=False)\n",
    "\n",
    "sample_images = []\n",
    "sample_captions = []\n",
    "for i in sample_indices:\n",
    "    image, label = val_dataset[i]\n",
    "    pred_label = val_pred_labels[i]\n",
    "    sample_images.append(image)\n",
    "    sample_captions.append(f\"gt: {label} | pred: {pred_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed6fc2c-0b95-42a3-a8c5-447e7de403e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "9ed6fc2c-0b95-42a3-a8c5-447e7de403e5",
    "outputId": "d919c8a7-961f-4042-ea81-e7f1aae82ca7"
   },
   "outputs": [],
   "source": [
    "show_images_with_captions(sample_images, sample_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a59920b-df4f-4cbf-a2c2-529d5dd58cc9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2a59920b-df4f-4cbf-a2c2-529d5dd58cc9",
    "outputId": "0e67878d-6005-4b93-fbdf-6782284499c2"
   },
   "outputs": [],
   "source": [
    "print((val_labels != val_pred_labels).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zyh3S0Z_Ope1",
   "metadata": {
    "id": "zyh3S0Z_Ope1"
   },
   "source": [
    "Посмотрим, как обстоит дело с устойчивостью моделей, например, к смещениям:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff3c791-37f4-478b-9e4c-8f1adc6aa711",
   "metadata": {
    "id": "1ff3c791-37f4-478b-9e4c-8f1adc6aa711"
   },
   "outputs": [],
   "source": [
    "def shift_image(image, min_shift=3, max_shift=6):\n",
    "    shift = np.random.randint(min_shift, max_shift+1)\n",
    "\n",
    "    output = np.zeros_like(image)\n",
    "    p = np.random.uniform()\n",
    "    pad_left = pad_right = pad_top = pad_bottom = 0\n",
    "    \n",
    "    if p <= 0.25:  # <-\n",
    "        output[:, :-shift] = image[:, shift:]\n",
    "    elif p < 0.5:  # ->\n",
    "        output[:, shift:] = image[:, :-shift]\n",
    "    elif p < 0.75: # ^\n",
    "        output[:-shift, :] = image[shift:, :]\n",
    "    else:          # v\n",
    "        output[shift:, :] = image[:-shift, :]\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mY1GRMVL3Zsj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "mY1GRMVL3Zsj",
    "outputId": "1a0966d7-1a31-4c85-a24d-efd301d2cb69"
   },
   "outputs": [],
   "source": [
    "# i = np.random.choice(np.where(val_labels == val_pred_labels)[0], size=1)[0]\n",
    "i = np.random.choice(len(val_dataset), size=1)[0]\n",
    "\n",
    "image = val_dataset[i][0]\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "EYCSmIzR3BhV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "EYCSmIzR3BhV",
    "outputId": "8603d4d4-49b7-428a-f5b8-c6adc2ad9253"
   },
   "outputs": [],
   "source": [
    "plt.imshow(shift_image(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac10db31-2bd7-4361-81aa-ec1d2c51a9c2",
   "metadata": {
    "id": "ac10db31-2bd7-4361-81aa-ec1d2c51a9c2"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nxDzx-8_3Ec2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nxDzx-8_3Ec2",
    "outputId": "1dd1b9c0-91e5-4db7-87f8-32b15daaa7df"
   },
   "outputs": [],
   "source": [
    "model.eval();\n",
    "my_cnn.eval();\n",
    "\n",
    "for j in range(10):\n",
    "    tensor = image_to_tensor(shift_image(image)).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds_fcn = model(tensor.view(1, -1))\n",
    "    label_fcn = preds_fcn.cpu().numpy().ravel().argmax()\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        preds_cnn = my_cnn(tensor)\n",
    "    label_cnn = preds_cnn.cpu().numpy().ravel().argmax()\n",
    "\n",
    "    print(label_fcn, label_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pVJAWcQY3EFk",
   "metadata": {
    "id": "pVJAWcQY3EFk"
   },
   "source": [
    "Как видим, природа сверточного слоя делает его более устойчивым к смещению (translation invariance), что и делает его таким полезным при работе с изображениями (и другими \"вытянутыми\" сигналами)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9zP6VKF95yuT",
   "metadata": {
    "id": "9zP6VKF95yuT"
   },
   "source": [
    "## 5. (bonus) Различные способы организации слоев в pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abZq6BIU6GQS",
   "metadata": {
    "id": "abZq6BIU6GQS"
   },
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NRLPxQAg7V-Y",
   "metadata": {
    "id": "NRLPxQAg7V-Y"
   },
   "outputs": [],
   "source": [
    "x = torch.randn(1, 1, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mi2-cCkS51q2",
   "metadata": {
    "id": "mi2-cCkS51q2"
   },
   "outputs": [],
   "source": [
    "my_cnn_seq = Sequential(        # b x 1 x 28 x 28\n",
    "    Conv2d(1, 8, (3, 3), 1, 1), # b x 8 x 28 x 28\n",
    "    ReLU(inplace=True),         # ...\n",
    "    BatchNorm2d(8),             # ...\n",
    "    MaxPool2d((2, 2)),          # b x 8 x 14 x 14\n",
    "    Conv2d(8, 32, (3, 3), 1, 1),# b x 32 x 14 x 14   \n",
    "    ReLU(inplace=True),         # ...\n",
    "    BatchNorm2d(32),            # ...\n",
    "    MaxPool2d((2, 2)),          # b x 32 x 7 x 7\n",
    "    Conv2d(32, 64, (3, 3), 1, 1),   # b x 64 x 7 x 7\n",
    "    ReLU(inplace=True),         # ...\n",
    "    AvgPool2d((7, 7)),          # b x 64 x 1 x 1\n",
    "    Flatten(),                  # b x 64\n",
    "    Linear(64, 10)              # b x 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8lBdE86E59fV",
   "metadata": {
    "id": "8lBdE86E59fV"
   },
   "outputs": [],
   "source": [
    "class MyCNNBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features, relu=True, bn=True, maxpool=True):\n",
    "        super(MyCNNBlock, self).__init__()\n",
    "\n",
    "        self.conv = Conv2d(in_features, out_features, (3, 3), 1, 1)\n",
    "        self.relu = ReLU(inplace=True) if relu else nn.Identity()\n",
    "        self.bn = BatchNorm2d(out_features) if bn else nn.Identity()\n",
    "        self.maxpool = MaxPool2d((2, 2)) if maxpool else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y1 = self.conv(x)\n",
    "        y2 = self.relu(y1)\n",
    "        y3 = self.bn(y2)\n",
    "        y4 = self.maxpool(y3)\n",
    "        return y4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gCNxMM9c6D_F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCNxMM9c6D_F",
    "outputId": "5f0f977f-1f38-4402-9370-a21cb9413182"
   },
   "outputs": [],
   "source": [
    "block = MyCNNBlock(1, 8)\n",
    "block(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gZZAh0PV7jOY",
   "metadata": {
    "id": "gZZAh0PV7jOY"
   },
   "source": [
    "* Больше гибкости в работе с промежуточными значениями\n",
    "* Можно делать \"непрямое\" течение тензоров (ResNet)\n",
    "* Проще эксперименты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TzLS2Lf_7DH0",
   "metadata": {
    "id": "TzLS2Lf_7DH0"
   },
   "outputs": [],
   "source": [
    "my_cnn_blocked = Sequential(\n",
    "    MyCNNBlock(1, 8),\n",
    "    MyCNNBlock(8, 32),\n",
    "    MyCNNBlock(32, 64, bn=False, maxpool=False),\n",
    "    AvgPool2d((7, 7)),          # b x 64 x 1 x 1\n",
    "    Flatten(),                  # b x 64\n",
    "    Linear(64, 10)              # b x 10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Yi1cgbTc7DlI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yi1cgbTc7DlI",
    "outputId": "5ef90d95-9244-4d27-9b88-f5f4225ec96a"
   },
   "outputs": [],
   "source": [
    "my_cnn_blocked(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BjbF9fFi8a5g",
   "metadata": {
    "id": "BjbF9fFi8a5g"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
